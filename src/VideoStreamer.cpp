#include "VideoStreamer.h"
#include <iostream>
#include <vector>
#include <chrono>
#include <opencv2/imgcodecs.hpp>
#include <sstream>

using namespace std;
using namespace std::chrono_literals;

VideoStreamer::VideoStreamer() : width_(1920), height_(1080), fps_(30) {
    // åˆå§‹åŒ–
    // æ³¨é‡Šæ‰è‡ªåŠ¨åŠ è½½æ ‡å®šæ•°æ®çš„é€»è¾‘ï¼Œè®©ç”¨æˆ·æ‰‹åŠ¨é€‰æ‹©æ˜¯å¦åŠ è½½
    // std::ifstream file(calibrationFilePath_);
    // if (file.good()) {
    //     file.close();
    //     loadHomography(calibrationFilePath_);
    // }
    
    // å¯ç”¨ä¿å­˜æ ‡å®šå›¾åƒåŠŸèƒ½
    cameraCalibrator_.setSaveCalibrationImages(true);
    std::cout << "Camera calibrator initialized, saveCalibrationImages set to true" << std::endl;
    
    // åˆå§‹åŒ–åŒåˆ†è¾¨ç‡è®¾ç½®
    displayWidth_ = 960;     // æ˜¾ç¤ºåˆ†è¾¨ç‡ï¼š16:9æ¯”ä¾‹
    displayHeight_ = 540;
    detectionWidth_ = 1920;  // æ£€æµ‹åˆ†è¾¨ç‡ï¼šé«˜ç²¾åº¦ï¼ˆå°†æ ¹æ®æ‘„åƒå¤´å®é™…èƒ½åŠ›è°ƒæ•´ï¼‰
    detectionHeight_ = 1080;
}

VideoStreamer::~VideoStreamer() {
    stop();
}

bool VideoStreamer::initialize(int camera_id, int width, int height, int fps) {
    // å…³é—­å½“å‰æ‘„åƒå¤´
    if (cap_.isOpened()) {
        cap_.release();
    }
    
    // å¦‚æœæŒ‡å®šäº†æ‘„åƒå¤´IDï¼Œåˆ™ä½¿ç”¨æŒ‡å®šçš„æ‘„åƒå¤´
    if (camera_id >= 0) {
        if (!cap_.open(camera_id, cv::CAP_V4L2)) {
            cerr << "Error: Could not open camera " << camera_id << " with V4L2 backend" << endl;
            return false;
        }
    } else {
        // å¦åˆ™å°è¯•è‡ªåŠ¨æ£€æµ‹æ‘„åƒå¤´
        if (!autoDetectCamera()) {
            std::cerr << "Error: Could not auto-detect any camera device" << std::endl;
            std::cout << "Using simulation mode instead" << std::endl;
            
            // åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿå›¾åƒ
            frame_ = cv::Mat(height, width, CV_8UC3, cv::Scalar(200, 200, 200));
            
            // åœ¨å›¾åƒä¸Šç»˜åˆ¶æ–‡å­—
            cv::putText(frame_, "Simulation Mode - No Camera", cv::Point(50, height/2 - 30), 
                        cv::FONT_HERSHEY_SIMPLEX, 0.8, cv::Scalar(0, 0, 0), 2);
            cv::putText(frame_, "Testing Matrix Display & Export", cv::Point(50, height/2 + 30), 
                        cv::FONT_HERSHEY_SIMPLEX, 0.8, cv::Scalar(0, 0, 0), 2);
            
            // åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„å•åº”æ€§çŸ©é˜µ
            cv::Mat simulatedMatrix = (cv::Mat_<double>(3, 3) << 
                1.2, 0.1, -50.5,
                0.05, 1.3, -30.2,
                0.001, 0.002, 1.0);
            
            // è®¾ç½®åˆ° HomographyMapper ä¸­
            homographyMapper_.setHomographyMatrix(simulatedMatrix);
            
            // æ ‡è®°ä¸ºå·²æ ‡å®šçŠ¶æ€
            homographyMapper_.setCalibrated(true);
            
            // è¿”å›æˆåŠŸ
            return true;
        }
    }
    
    // æ£€æŸ¥æ‘„åƒå¤´æ˜¯å¦æˆåŠŸæ‰“å¼€
    if (!cap_.isOpened()) {
        std::cerr << "Failed to initialize camera" << std::endl;
        return false;
    }
    
    width_ = width;
    height_ = height;
    fps_ = fps;

    // é¦–å…ˆæ£€æŸ¥æ‘„åƒå¤´æ”¯æŒçš„åˆ†è¾¨ç‡
    cout << "ğŸ” [RESOLUTION CHECK] æ£€æŸ¥æ‘„åƒå¤´æ”¯æŒçš„åˆ†è¾¨ç‡..." << endl;
    auto supportedResolutions = getSupportedResolutions();
    
    // é«˜æ€§èƒ½æ‘„åƒå¤´è®¾ç½®
    cout << "ğŸš€ [HIGH PERFORMANCE SETUP] é…ç½®é«˜æ€§èƒ½æ‘„åƒå¤´å‚æ•°..." << endl;
    cout << "ğŸ“ [RESOLUTION SET] å°è¯•è®¾ç½®åˆ†è¾¨ç‡ä¸º " << width_ << "x" << height_ << endl;
    
    // åŸºæœ¬å‚æ•°è®¾ç½®
    cap_.set(cv::CAP_PROP_FRAME_WIDTH, width_);
    cap_.set(cv::CAP_PROP_FRAME_HEIGHT, height_);
    cap_.set(cv::CAP_PROP_FPS, fps_);
    cap_.set(cv::CAP_PROP_FOURCC, cv::VideoWriter::fourcc('M', 'J', 'P', 'G'));
    
    // é«˜æ€§èƒ½ä¼˜åŒ–è®¾ç½®
    cap_.set(cv::CAP_PROP_BUFFERSIZE, 1);  // å‡å°‘ç¼“å†²åŒºå¤§å°ï¼Œé™ä½å»¶è¿Ÿ
    cap_.set(cv::CAP_PROP_AUTO_EXPOSURE, 0.25);  // ç¦ç”¨è‡ªåŠ¨æ›å…‰ä»¥æé«˜å¸§ç‡ç¨³å®šæ€§
    cap_.set(cv::CAP_PROP_AUTOFOCUS, 0);  // ç¦ç”¨è‡ªåŠ¨å¯¹ç„¦ä»¥å‡å°‘å¤„ç†æ—¶é—´
    
    cout << "âš¡ [PERFORMANCE] å·²å¯ç”¨é«˜æ€§èƒ½ä¼˜åŒ–è®¾ç½®" << endl;

    // éªŒè¯å‚æ•°
    double actual_width = cap_.get(cv::CAP_PROP_FRAME_WIDTH);
    double actual_height = cap_.get(cv::CAP_PROP_FRAME_HEIGHT);
    double actual_fps = cap_.get(cv::CAP_PROP_FPS);

    cout << "Camera initialized with parameters:" << endl;
    cout << "  Resolution: " << actual_width << "x" << actual_height << endl;
    cout << "  FPS: " << actual_fps << endl;

    // éªŒè¯åˆ†è¾¨ç‡è®¾ç½®æ˜¯å¦æˆåŠŸ
    if (abs(actual_width - width) > 50 || abs(actual_height - height) > 50) {
        cout << "âš ï¸ [RESOLUTION WARNING] è¯·æ±‚åˆ†è¾¨ç‡ " << width << "x" << height 
             << " ä¸è¢«æ”¯æŒï¼Œæ‘„åƒå¤´ä½¿ç”¨ " << actual_width << "x" << actual_height << endl;
        
        // åŠ¨æ€é€‚é…æ£€æµ‹åˆ†è¾¨ç‡åˆ°æ‘„åƒå¤´å®é™…åˆ†è¾¨ç‡
        detectionWidth_ = static_cast<int>(actual_width);
        detectionHeight_ = static_cast<int>(actual_height);
        cout << "ğŸ”§ [AUTO ADAPT] æ£€æµ‹åˆ†è¾¨ç‡è‡ªåŠ¨è°ƒæ•´ä¸º: " 
             << detectionWidth_ << "x" << detectionHeight_ << endl;
    } else {
        cout << "âœ… [RESOLUTION OK] åˆ†è¾¨ç‡è®¾ç½®æˆåŠŸ: " << actual_width << "x" << actual_height << endl;
    }

    // å®‰å…¨åˆå§‹åŒ–Matå¯¹è±¡ - é˜²æ­¢æœªåˆå§‹åŒ–çš„Matå¯¼è‡´å¼‚å¸¸
    try {
        cv::Mat testFrame;
        if (cap_.read(testFrame) && !testFrame.empty()) {
            std::lock_guard<std::mutex> lock(mutex_);
            frame_ = testFrame.clone();
            detectionFrame_ = testFrame.clone();
            std::cout << "âœ… [MAT INIT] Mat objects initialized safely with dimensions: " 
                      << testFrame.cols << "x" << testFrame.rows << std::endl;
        } else {
            std::cerr << "âš ï¸ [MAT INIT] Unable to read initial frame for Mat initialization" << std::endl;
            // åˆ›å»ºç©ºçš„Matå¯¹è±¡é¿å…æœªåˆå§‹åŒ–çŠ¶æ€
            std::lock_guard<std::mutex> lock(mutex_);
            frame_ = cv::Mat();
            detectionFrame_ = cv::Mat();
        }
    } catch (const cv::Exception& e) {
        std::cerr << "âŒ [MAT INIT] OpenCV error during Mat initialization: " << e.what() << std::endl;
        std::lock_guard<std::mutex> lock(mutex_);
        frame_ = cv::Mat();
        detectionFrame_ = cv::Mat();
    } catch (const std::exception& e) {
        std::cerr << "âŒ [MAT INIT] Error during Mat initialization: " << e.what() << std::endl;
        std::lock_guard<std::mutex> lock(mutex_);
        frame_ = cv::Mat();
        detectionFrame_ = cv::Mat();
    }

    return true;
}

bool VideoStreamer::autoDetectCamera() {
    // å°è¯•ç›´æ¥ä½¿ç”¨è®¾å¤‡è·¯å¾„æ‰“å¼€æ‘„åƒå¤´
    std::vector<std::string> device_paths = {
        "/dev/video0",
        "/dev/video2"
    };
    
    for (const auto& device_path : device_paths) {
        std::cout << "Trying to open camera device: " << device_path << std::endl;
        
        // ç›´æ¥å°†æ‘„åƒå¤´æ‰“å¼€åˆ°æˆ‘ä»¬çš„ä¸»æ•è·å™¨ä¸­
        // è®¾ç½®æ‘„åƒå¤´å‚æ•°ä»¥ä½¿ç”¨MJPEGæ ¼å¼
        cap_.set(cv::CAP_PROP_FOURCC, cv::VideoWriter::fourcc('M', 'J', 'P', 'G'));
        
        // ç›´æ¥ä½¿ç”¨è®¾å¤‡è·¯å¾„æ‰“å¼€æ‘„åƒå¤´
        if (cap_.open(device_path, cv::CAP_V4L2)) {
            // å°è¯•æ•è·ä¸€å¸§æ¥éªŒè¯è®¾å¤‡
            cv::Mat test_frame;
            cap_ >> test_frame;
            
            if (!test_frame.empty()) {
                std::cout << "Successfully opened camera device: " << device_path << " (MJPEG mode)" << std::endl;
                
                // æ‰“å°æ‘„åƒå¤´é»˜è®¤ä¿¡æ¯
                double width = cap_.get(cv::CAP_PROP_FRAME_WIDTH);
                double height = cap_.get(cv::CAP_PROP_FRAME_HEIGHT);
                double fps = cap_.get(cv::CAP_PROP_FPS);
                std::cout << "Camera default info - Width: " << width << ", Height: " << height << ", FPS: " << fps << std::endl;
                
                // æ‘„åƒå¤´æˆåŠŸæ‰“å¼€å¹¶æ•è·äº†ä¸€å¸§ï¼Œè¿”å›æˆåŠŸ
                return true;
            } else {
                std::cerr << "Failed to capture frame from camera device: " << device_path << std::endl;
                // å…³é—­æ‘„åƒå¤´å¹¶å°è¯•ä¸‹ä¸€ä¸ªè®¾å¤‡
                cap_.release();
            }
        } else {
            std::cerr << "Failed to open camera device: " << device_path << std::endl;
        }
    }
    
    // å¦‚æœæ‰€æœ‰è®¾å¤‡è·¯å¾„éƒ½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ç´¢å¼•
    std::vector<int> indices = {0, 1, 2, 3, 4};
    for (int idx : indices) {
        std::cout << "Trying to open camera with index: " << idx << std::endl;
        
        // è®¾ç½®æ‘„åƒå¤´å‚æ•°ä»¥ä½¿ç”¨MJPEGæ ¼å¼
        cap_.set(cv::CAP_PROP_FOURCC, cv::VideoWriter::fourcc('M', 'J', 'P', 'G'));
        
        if (cap_.open(idx, cv::CAP_V4L2)) {
            cv::Mat test_frame;
            cap_ >> test_frame;
            
            if (!test_frame.empty()) {
                std::cout << "Successfully opened camera with index: " << idx << std::endl;
                return true;
            } else {
                std::cerr << "Failed to capture frame from camera with index: " << idx << std::endl;
                cap_.release();
            }
        } else {
            std::cerr << "Failed to open camera with index: " << idx << std::endl;
        }
    }
    
    return false; // æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ‘„åƒå¤´è®¾å¤‡
}

std::vector<std::pair<int, int>> VideoStreamer::getSupportedResolutions() {
    // é«˜æ€§èƒ½åˆ†è¾¨ç‡åˆ—è¡¨ - ä¼˜å…ˆæ”¯æŒé«˜åˆ†è¾¨ç‡ä»¥è·å¾—æ›´å¥½çš„å›¾åƒè´¨é‡
    std::vector<std::pair<int, int>> resolutions = {
        {1920, 1080},  // Full HD - ä¼˜å…ˆ
        {1280, 720},   // HD
        {1280, 960},   // SXGA-
        {1024, 768},   // XGA
        {800, 600},    // SVGA
        {640, 480}     // VGA - å…¼å®¹æ€§ä¿ç•™
    };
    
    // å¦‚æœæ‘„åƒå¤´æœªæ‰“å¼€ï¼Œè¿”å›é»˜è®¤åˆ—è¡¨
    if (!cap_.isOpened()) {
        return resolutions;
    }
    
    // éªŒè¯æ‘„åƒå¤´æ”¯æŒçš„åˆ†è¾¨ç‡
    std::vector<std::pair<int, int>> supported_resolutions;
    
    // ä¿å­˜å½“å‰åˆ†è¾¨ç‡
    double current_width = cap_.get(cv::CAP_PROP_FRAME_WIDTH);
    double current_height = cap_.get(cv::CAP_PROP_FRAME_HEIGHT);
    
    // æ£€æŸ¥æ¯ä¸ªåˆ†è¾¨ç‡æ˜¯å¦æ”¯æŒ
    for (const auto& res : resolutions) {
        // å°è¯•è®¾ç½®åˆ†è¾¨ç‡
        cap_.set(cv::CAP_PROP_FRAME_WIDTH, res.first);
        cap_.set(cv::CAP_PROP_FRAME_HEIGHT, res.second);
        
        // è·å–å®é™…è®¾ç½®çš„åˆ†è¾¨ç‡
        double actual_width = cap_.get(cv::CAP_PROP_FRAME_WIDTH);
        double actual_height = cap_.get(cv::CAP_PROP_FRAME_HEIGHT);
        
        // å¦‚æœå®é™…åˆ†è¾¨ç‡ä¸è¯·æ±‚çš„åˆ†è¾¨ç‡æ¥è¿‘ï¼Œåˆ™è®¤ä¸ºæ”¯æŒ
        if (std::abs(actual_width - res.first) < 10 && std::abs(actual_height - res.second) < 10) {
            supported_resolutions.push_back({static_cast<int>(actual_width), static_cast<int>(actual_height)});
            cout << "Supported resolution: " << actual_width << "x" << actual_height << endl;
        }
    }
    
    // æ¢å¤åŸå§‹åˆ†è¾¨ç‡
    cap_.set(cv::CAP_PROP_FRAME_WIDTH, current_width);
    cap_.set(cv::CAP_PROP_FRAME_HEIGHT, current_height);
    
    return supported_resolutions.empty() ? resolutions : supported_resolutions;
}

bool VideoStreamer::setResolution(int width, int height) {
    if (!cap_.isOpened()) {
        cerr << "Error: Camera not initialized" << endl;
        return false;
    }
    
    // è®¾ç½®æ–°åˆ†è¾¨ç‡
    cap_.set(cv::CAP_PROP_FRAME_WIDTH, width);
    cap_.set(cv::CAP_PROP_FRAME_HEIGHT, height);
    
    // éªŒè¯åˆ†è¾¨ç‡æ˜¯å¦è®¾ç½®æˆåŠŸ
    double actual_width = cap_.get(cv::CAP_PROP_FRAME_WIDTH);
    double actual_height = cap_.get(cv::CAP_PROP_FRAME_HEIGHT);
    
    // æ›´æ–°å†…éƒ¨åˆ†è¾¨ç‡å˜é‡
    width_ = static_cast<int>(actual_width);
    height_ = static_cast<int>(actual_height);
    
    cout << "Resolution set to: " << width_ << "x" << height_ << endl;
    
    // å¦‚æœå®é™…åˆ†è¾¨ç‡ä¸è¯·æ±‚çš„åˆ†è¾¨ç‡æ¥è¿‘ï¼Œåˆ™è®¤ä¸ºè®¾ç½®æˆåŠŸ
    return (std::abs(actual_width - width) < 10 && std::abs(actual_height - height) < 10);
}

std::pair<int, int> VideoStreamer::getCurrentResolution() {
    if (!cap_.isOpened()) {
        return {width_, height_}; // è¿”å›å†…éƒ¨å­˜å‚¨çš„åˆ†è¾¨ç‡
    }
    
    // è·å–å½“å‰åˆ†è¾¨ç‡
    double width = cap_.get(cv::CAP_PROP_FRAME_WIDTH);
    double height = cap_.get(cv::CAP_PROP_FRAME_HEIGHT);
    
    return {static_cast<int>(width), static_cast<int>(height)};
}

void VideoStreamer::start() {
    if (!cap_.isOpened()) {
        cerr << "Error: Camera not initialized" << endl;
        return;
    }
    
    running_ = true;
    worker_ = thread(&VideoStreamer::captureThread, this);
    
    // æ€§èƒ½ä¼˜åŒ–ï¼šå¯åŠ¨å¹¿æ’­çº¿ç¨‹æ—¶æ·»åŠ å¸§ç‡æ§åˆ¶
    thread broadcast_thread([this]() {
        // é«˜æ€§èƒ½æ¨¡å¼ - ä½¿ç”¨åŸå§‹FPSè®¾ç½®ï¼Œä¸è¿›è¡Œé™é€Ÿ
        int targetFPS = fps_;
        
        std::cout << "ğŸš€ [HIGH PERFORMANCE MODE] Target FPS: " << targetFPS << " (High frame rate mode enabled)" << std::endl;
        
        auto lastFrameTime = std::chrono::high_resolution_clock::now();
        auto targetFrameInterval = std::chrono::microseconds(1000000 / targetFPS); // ç›®æ ‡å¸§é—´éš”
        
        // æ€§èƒ½ç›‘æ§å˜é‡
        int broadcastCount = 0;
        auto performanceReportTime = std::chrono::steady_clock::now();
        
        while (running_) {
            auto frameStart = std::chrono::high_resolution_clock::now();
            
            // æ‰§è¡Œå¸§å¹¿æ’­
            broadcastFrame();
            broadcastCount++;
            
            auto frameEnd = std::chrono::high_resolution_clock::now();
            
            // ç²¾ç¡®çš„å¸§ç‡æ§åˆ¶ - åªåœ¨å¿…è¦æ—¶ç¡çœ 
            auto elapsedSinceLastFrame = frameEnd - lastFrameTime;
            auto sleepTime = targetFrameInterval - elapsedSinceLastFrame;
            
            if (sleepTime > std::chrono::microseconds(100)) { // åªæœ‰è¶…è¿‡100å¾®ç§’æ‰ç¡çœ 
                std::this_thread::sleep_for(sleepTime);
            } else {
                // ä½¿ç”¨yieldè®©å‡ºCPUæ—¶é—´ç‰‡ï¼Œä½†ä¸å¼ºåˆ¶ç¡çœ 
                std::this_thread::yield();
            }
            
            lastFrameTime = std::chrono::high_resolution_clock::now();
            
            // æ¯10ç§’è¾“å‡ºä¸€æ¬¡æ€§èƒ½æŠ¥å‘Š
            auto broadcastReportTime = std::chrono::steady_clock::now();
            if (std::chrono::duration_cast<std::chrono::seconds>(broadcastReportTime - performanceReportTime).count() >= 10) {
                double actualFPS = broadcastCount / 10.0;
                std::cout << "ğŸ¯ [HIGH PERFORMANCE] Actual FPS: " << std::fixed << std::setprecision(2) << actualFPS 
                          << " (Target: " << targetFPS << ")" << std::endl;
                
                // é‡ç½®è®¡æ•°å™¨
                broadcastCount = 0;
                performanceReportTime = broadcastReportTime;
            }
        }
    });
    broadcast_thread.detach();
    
    cout << "Video stream started" << endl;
}

void VideoStreamer::stop() {
    if (running_) {
        running_ = false;
        if (worker_.joinable()) {
            worker_.join();
        }
    }
    
    {
        std::lock_guard<std::mutex> lock(conn_mutex_);
        connections_.clear();
    }
    
    if (cap_.isOpened()) {
        cap_.release();
    }
    
    cout << "Video streaming stopped" << endl;
}

void VideoStreamer::handleWebSocket(const crow::request& req, Connection conn) {
    // æ·»åŠ è¿æ¥åˆ°é›†åˆ
    {
        std::lock_guard<std::mutex> lock(conn_mutex_);
        connections_.insert(conn);
        std::cout << "WebSocket connection added to VideoStreamer, total connections: " << connections_.size() << std::endl;
    }
    
    // å‘é€æ‘„åƒå¤´ä¿¡æ¯ç»™å®¢æˆ·ç«¯
    sendCameraInfo(conn);
}

void VideoStreamer::removeWebSocketConnection(Connection conn) {
    std::lock_guard<std::mutex> lock(conn_mutex_);
    auto it = connections_.find(conn);
    if (it != connections_.end()) {
        connections_.erase(it);
        std::cout << "WebSocket connection removed from VideoStreamer, remaining connections: " << connections_.size() << std::endl;
    }
}

void VideoStreamer::sendCameraInfo(Connection conn) {
    if (!conn) return;
    
    try {
        // è·å–æ‘„åƒå¤´æ”¯æŒçš„åˆ†è¾¨ç‡
        auto resolutions = getSupportedResolutions();
        auto current_res = getCurrentResolution();
        
        // æ„å»ºåˆ†è¾¨ç‡JSONæ•°ç»„
        std::string res_array = "[";
        for (size_t i = 0; i < resolutions.size(); ++i) {
            res_array += "{\"width\":"
                      + std::to_string(resolutions[i].first) + ",\"height\":"
                      + std::to_string(resolutions[i].second) + "}";
            if (i < resolutions.size() - 1) {
                res_array += ",";
            }
        }
        res_array += "]";
        
        // è·å–æ£‹ç›˜æ ¼å‚æ•°
        cv::Size boardSize = cameraCalibrator_.getBoardSize();
        float squareSize = cameraCalibrator_.getSquareSize();
        
        // æ„å»ºæ‘„åƒå¤´ä¿¡æ¯æ¶ˆæ¯
        std::string info_message = std::string("{\"type\":\"camera_info\",")
                              + "\"current_width\":"
                              + std::to_string(current_res.first) + ","
                              + "\"current_height\":"
                              + std::to_string(current_res.second) + ","
                              + "\"fps\":"
                              + std::to_string(fps_) + ","
                              + "\"calibration_mode\":"
                              + (calibrationMode_ ? "true" : "false") + ","
                              + "\"calibrated\":"
                              + (homographyMapper_.isCalibrated() ? "true" : "false") + ","
                              + "\"board_width\":"
                              + std::to_string(boardSize.width) + ","
                              + "\"board_height\":"
                              + std::to_string(boardSize.height) + ","
                              + "\"square_size\":"
                              + std::to_string(int(squareSize * 1000)) + ","
                              + "\"resolutions\":"
                              + res_array + "}";
        
        // å‘é€æ¶ˆæ¯
        conn->send_text(info_message);
        
    } catch (const std::exception& e) {
        std::cerr << "Error sending camera info: " << e.what() << std::endl;
    }
}

// å•åº”æ€§çŸ©é˜µæ ‡å®šç›¸å…³æ–¹æ³•çš„å®ç°
bool VideoStreamer::addCalibrationPoint(const cv::Point2f& imagePoint, const cv::Point2f& groundPoint) {
    homographyMapper_.addCalibrationPoint(imagePoint, groundPoint);
    return true;
}

bool VideoStreamer::removeLastCalibrationPoint() {
    auto points = homographyMapper_.getCalibrationPoints();
    if (points.empty()) {
        return false;
    }
    
    homographyMapper_.clearCalibrationPoints();
    
    // é‡æ–°æ·»åŠ é™¤äº†æœ€åä¸€ä¸ªä¹‹å¤–çš„æ‰€æœ‰ç‚¹
    for (size_t i = 0; i < points.size() - 1; ++i) {
        homographyMapper_.addCalibrationPoint(points[i].first, points[i].second);
    }
    
    return true;
}

bool VideoStreamer::clearCalibrationPoints() {
    homographyMapper_.clearCalibrationPoints();
    return true;
}

bool VideoStreamer::computeHomography() {
    return homographyMapper_.computeHomography();
}

bool VideoStreamer::saveHomography(const std::string& filename) {
    return homographyMapper_.saveHomography(filename.empty() ? calibrationFilePath_ : filename);
}

bool VideoStreamer::loadHomography(const std::string& filename) {
    return homographyMapper_.loadHomography(filename.empty() ? calibrationFilePath_ : filename);
}

cv::Point2f VideoStreamer::imageToGround(const cv::Point2f& imagePoint) {
    return homographyMapper_.imageToGround(imagePoint);
}

cv::Point2f VideoStreamer::groundToImage(const cv::Point2f& groundPoint) {
    return homographyMapper_.groundToImage(groundPoint);
}

bool VideoStreamer::isCalibrated() const {
    return homographyMapper_.isCalibrated();
}

std::vector<std::pair<cv::Point2f, cv::Point2f>> VideoStreamer::getCalibrationPoints() const {
    return homographyMapper_.getCalibrationPoints();
}

cv::Mat VideoStreamer::getHomographyMatrix() const {
    return homographyMapper_.getHomographyMatrix();
}

// ArUco æ ‡è®°ç›¸å…³æ–¹æ³•å®ç°
bool VideoStreamer::toggleArUcoMode() {
    arucoMode_ = !arucoMode_;
    return arucoMode_;
}

bool VideoStreamer::isArUcoMode() const {
    return arucoMode_;
}

bool VideoStreamer::detectArUcoMarkers(cv::Mat& frame) {
    if (!arucoMode_) return false;
    
    // æ£€æµ‹æ ‡è®°
    std::vector<int> markerIds;
    std::vector<std::vector<cv::Point2f>> markerCorners;
    
    bool detected = homographyMapper_.detectArUcoMarkers(frame, markerIds, markerCorners);
    
    // å‘é€å®æ—¶æ£€æµ‹ç»“æœç»™å‰ç«¯
    static int lastMarkerCount = -1;
    int currentMarkerCount = markerIds.size();
    
    // åªæœ‰å½“æ£€æµ‹åˆ°çš„æ ‡è®°æ•°é‡å‘ç”Ÿå˜åŒ–æ—¶æ‰å‘é€æ›´æ–°ï¼ˆé¿å…é¢‘ç¹å‘é€ï¼‰
    if (currentMarkerCount != lastMarkerCount) {
        // æ„å»ºæ£€æµ‹ç»“æœæ¶ˆæ¯ï¼ŒåŒ…å«è¯¦ç»†çš„æ ‡è®°ä¿¡æ¯
        bool homographyLoaded = !getHomographyMatrix().empty();
        std::stringstream aruco_message;
        aruco_message << "{\"type\":\"aruco_detection_update\","
                     << "\"detected_markers\":" << currentMarkerCount << ","
                     << "\"homography_loaded\":" << (homographyLoaded ? "true" : "false") << ","
                     << "\"matrix_status\":\"" << (homographyLoaded ? "å·²æ ‡å®š" : "æœªæ ‡å®š") << "\"";
        
        // å¦‚æœæ£€æµ‹åˆ°æ ‡è®°ï¼Œæ·»åŠ è¯¦ç»†ä¿¡æ¯
        if (currentMarkerCount > 0) {
            aruco_message << ",\"markers\":[";
            for (size_t i = 0; i < markerIds.size(); i++) {
                int id = markerIds[i];
                
                // è®¡ç®—æ ‡è®°ä¸­å¿ƒ
                cv::Point2f center(0, 0);
                for (const auto& corner : markerCorners[i]) {
                    center += corner;
                }
                center *= 0.25f;
                
                aruco_message << "{\"id\":" << id 
                             << ",\"center\":{\"x\":" << center.x << ",\"y\":" << center.y << "}";
                
                // å¦‚æœå·²æ ‡å®šï¼Œæ·»åŠ åœ°é¢åæ ‡
                if (homographyLoaded) {
                    cv::Point2f groundPoint = imageToGround(center);
                    aruco_message << ",\"ground_coordinate\":{\"x\":" << groundPoint.x << ",\"y\":" << groundPoint.y << "}";
                }
                
                aruco_message << "}";
                if (i < markerIds.size() - 1) aruco_message << ",";
            }
            aruco_message << "]";
        }
        
        aruco_message << "}";
        
        // å‘é€æ¶ˆæ¯ç»™æ‰€æœ‰è¿æ¥çš„å®¢æˆ·ç«¯
        {
            std::lock_guard<std::mutex> lock(conn_mutex_);
            for (auto conn : connections_) {
                if (conn) {
                    try {
                        conn->send_text(aruco_message.str());
                    } catch (const std::exception& e) {
                        std::cerr << "Error sending ArUco detection update: " << e.what() << std::endl;
                    }
                }
            }
        }
        
        lastMarkerCount = currentMarkerCount;
        std::cout << "[ArUco æ£€æµ‹] æ›´æ–°: æ£€æµ‹åˆ° " << currentMarkerCount << " ä¸ªæ ‡è®°ï¼ŒçŸ©é˜µçŠ¶æ€: " 
                  << (homographyLoaded ? "å·²æ ‡å®š" : "æœªæ ‡å®š") << std::endl;
    }
    
    if (detected) {
        // ç»˜åˆ¶æ£€æµ‹åˆ°çš„æ ‡è®°ï¼ˆHomographyMapperä¼šå¤„ç†æ‰€æœ‰æ˜¾ç¤ºä¿¡æ¯ï¼‰
        homographyMapper_.drawDetectedMarkers(frame, markerIds, markerCorners);
    }
    
    return detected;
}

bool VideoStreamer::calibrateFromArUcoMarkers() {
    if (!arucoMode_) return false;
    
    std::lock_guard<std::mutex> lock(mutex_);
    if (frame_.empty()) return false;
    
    // ä½¿ç”¨å½“å‰å¸§å’Œæ ‡è®°åœ°é¢åæ ‡è¿›è¡Œæ ‡å®š
    return homographyMapper_.calibrateFromArUcoMarkers(frame_, homographyMapper_.getMarkerGroundCoordinates());
}

bool VideoStreamer::setMarkerGroundCoordinates(int markerId, const cv::Point2f& groundCoord) {
    homographyMapper_.setMarkerGroundCoordinates(markerId, groundCoord);
    return true;
}

bool VideoStreamer::saveMarkerCoordinates(const std::string& filename) {
    std::string targetFile = filename.empty() ? markerCoordinatesFilePath_ : filename;
    return homographyMapper_.saveMarkerGroundCoordinates(targetFile);
}

bool VideoStreamer::loadMarkerCoordinates(const std::string& filename) {
    std::string targetFile = filename.empty() ? markerCoordinatesFilePath_ : filename;
    return homographyMapper_.loadMarkerGroundCoordinates(targetFile);
}

void VideoStreamer::drawCalibrationPoints(cv::Mat& frame) {
    auto points = homographyMapper_.getCalibrationPoints();
    
    // ç»˜åˆ¶æ ‡å®šç‚¹
    for (size_t i = 0; i < points.size(); ++i) {
        // ç»˜åˆ¶å¤–åœˆ
        cv::circle(frame, points[i].first, 12, cv::Scalar(0, 255, 255), 2);
        // ç»˜åˆ¶å†…åœˆ
        cv::circle(frame, points[i].first, 5, cv::Scalar(0, 0, 255), -1);
        // ç»˜åˆ¶åå­—çº¿ - ä½¿ç”¨é’è‰²æ›¿ä»£ç»¿è‰²
        cv::line(frame, cv::Point(points[i].first.x - 15, points[i].first.y),
                 cv::Point(points[i].first.x + 15, points[i].first.y),
                 cv::Scalar(209, 206, 0), 1); // é’è‰² (0, 206, 209)
        cv::line(frame, cv::Point(points[i].first.x, points[i].first.y - 15),
                 cv::Point(points[i].first.x, points[i].first.y + 15),
                 cv::Scalar(209, 206, 0), 1); // é’è‰² (0, 206, 209)
        
        // ç»˜åˆ¶ç‚¹ç¼–å·
        cv::putText(frame, std::to_string(i + 1), 
                   cv::Point(points[i].first.x + 15, points[i].first.y - 10), 
                   cv::FONT_HERSHEY_SIMPLEX, 0.7, cv::Scalar(0, 0, 255), 2);
        
        // ç»˜åˆ¶åœ°é¢åæ ‡ - ä½¿ç”¨æ·±è“è‰²æ›¿ä»£çº¢è‰²
        std::string coordText = "(" + std::to_string(int(points[i].second.x)) + "," + 
                               std::to_string(int(points[i].second.y)) + ")";
        cv::putText(frame, coordText, 
                   cv::Point(points[i].first.x + 15, points[i].first.y + 15), 
                   cv::FONT_HERSHEY_SIMPLEX, 0.6, cv::Scalar(112, 25, 25), 2); // æ·±è“è‰² (25, 25, 112)
    }
    
    // å¦‚æœå·²ç»æ ‡å®šï¼Œç»˜åˆ¶ç½‘æ ¼çº¿æ¥æ˜¾ç¤ºæ ‡å®šæ•ˆæœ
    if (homographyMapper_.isCalibrated() && points.size() >= 4) {
        // ğŸ”§ ä¿®å¤ï¼šåŸºäºå®é™…æ ‡å®šç‚¹èŒƒå›´ç»˜åˆ¶æœ‰æ„ä¹‰çš„ç½‘æ ¼çº¿
        
        // æ‰¾åˆ°æ ‡å®šç‚¹çš„è¾¹ç•Œæ¡†
        float minX = std::numeric_limits<float>::max();
        float minY = std::numeric_limits<float>::max();
        float maxX = std::numeric_limits<float>::min();
        float maxY = std::numeric_limits<float>::min();
        
        for (const auto& point : points) {
            minX = std::min(minX, point.second.x);
            minY = std::min(minY, point.second.y);
            maxX = std::max(maxX, point.second.x);
            maxY = std::max(maxY, point.second.y);
        }
        
        // è®¡ç®—æ ‡å®šåŒºåŸŸçš„å®é™…å°ºå¯¸
        float rangeX = maxX - minX;
        float rangeY = maxY - minY;
        
        // ğŸ”§ ä¿®å¤ï¼šæ ¹æ®å®é™…èŒƒå›´ç¡®å®šåˆé€‚çš„ç½‘æ ¼é—´è·
        float gridSpacing = 50.0f; // åŸºç¡€ç½‘æ ¼é—´è·50mm
        
        // å¦‚æœæ ‡å®šåŒºåŸŸå¾ˆå¤§ï¼Œå¢åŠ ç½‘æ ¼é—´è·ï¼›å¦‚æœå¾ˆå°ï¼Œå‡å°‘ç½‘æ ¼é—´è·
        if (rangeX > 500 || rangeY > 500) {
            gridSpacing = 100.0f; // å¤§åŒºåŸŸä½¿ç”¨100mmé—´è·
        } else if (rangeX < 200 && rangeY < 200) {
            gridSpacing = 25.0f;  // å°åŒºåŸŸä½¿ç”¨25mmé—´è·
        }
        
        // ğŸ”§ ä¿®å¤ï¼šæ‰©å±•æ˜¾ç¤ºåŒºåŸŸï¼Œä½†ä¿æŒåˆç†çš„èŒƒå›´
        float expandRatio = 0.3f; // å‘å¤–æ‰©å±•30%
        minX -= rangeX * expandRatio;
        maxX += rangeX * expandRatio;
        minY -= rangeY * expandRatio;
        maxY += rangeY * expandRatio;
        
        // ğŸ”§ ä¿®å¤ï¼šå¯¹é½ç½‘æ ¼çº¿åˆ°åˆç†çš„åæ ‡å€¼
        // å°†è¾¹ç•Œå¯¹é½åˆ°ç½‘æ ¼é—´è·çš„å€æ•°
        float alignedMinX = std::floor(minX / gridSpacing) * gridSpacing;
        float alignedMaxX = std::ceil(maxX / gridSpacing) * gridSpacing;
        float alignedMinY = std::floor(minY / gridSpacing) * gridSpacing;
        float alignedMaxY = std::ceil(maxY / gridSpacing) * gridSpacing;
        
        // ğŸ”§ ä¿®å¤ï¼šç»˜åˆ¶æ°´å¹³ç½‘æ ¼çº¿ï¼ˆYåæ ‡å›ºå®šï¼‰
        for (float y = alignedMinY; y <= alignedMaxY; y += gridSpacing) {
            cv::Point2f start = groundToImage(cv::Point2f(alignedMinX, y));
            cv::Point2f end = groundToImage(cv::Point2f(alignedMaxX, y));
            
            // æ£€æŸ¥çº¿æ¡æ˜¯å¦åœ¨å›¾åƒèŒƒå›´å†…
            if ((start.x >= -50 && start.x <= frame.cols + 50) || (end.x >= -50 && end.x <= frame.cols + 50)) {
                if ((start.y >= -50 && start.y <= frame.rows + 50) || (end.y >= -50 && end.y <= frame.rows + 50)) {
                    
                    // ç»˜åˆ¶ç½‘æ ¼çº¿ - ä½¿ç”¨é’è‰²
                    cv::line(frame, start, end, cv::Scalar(209, 206, 0), 2, cv::LINE_AA); // é’è‰² BGR(209, 206, 0)
                    
                    // åœ¨åˆé€‚çš„ä½ç½®æ˜¾ç¤ºYåæ ‡å€¼
                    if (start.x >= 0 && start.x < frame.cols - 50 && start.y >= 15 && start.y < frame.rows - 5) {
                        cv::putText(frame, std::to_string(int(y)), 
                                   cv::Point(std::max(5.0f, start.x + 5), start.y - 5), 
                                   cv::FONT_HERSHEY_SIMPLEX, 0.4, cv::Scalar(209, 206, 0), 1, cv::LINE_AA);
                    }
                }
            }
        }
        
        // ğŸ”§ ä¿®å¤ï¼šç»˜åˆ¶å‚ç›´ç½‘æ ¼çº¿ï¼ˆXåæ ‡å›ºå®šï¼‰
        for (float x = alignedMinX; x <= alignedMaxX; x += gridSpacing) {
            cv::Point2f start = groundToImage(cv::Point2f(x, alignedMinY));
            cv::Point2f end = groundToImage(cv::Point2f(x, alignedMaxY));
            
            // æ£€æŸ¥çº¿æ¡æ˜¯å¦åœ¨å›¾åƒèŒƒå›´å†…
            if ((start.x >= -50 && start.x <= frame.cols + 50) || (end.x >= -50 && end.x <= frame.cols + 50)) {
                if ((start.y >= -50 && start.y <= frame.rows + 50) || (end.y >= -50 && end.y <= frame.rows + 50)) {
                    
                    // ç»˜åˆ¶ç½‘æ ¼çº¿ - ä½¿ç”¨é’è‰²
                    cv::line(frame, start, end, cv::Scalar(209, 206, 0), 2, cv::LINE_AA); // é’è‰² BGR(209, 206, 0)
                    
                    // åœ¨åˆé€‚çš„ä½ç½®æ˜¾ç¤ºXåæ ‡å€¼
                    if (start.x >= 5 && start.x < frame.cols - 30 && start.y >= 0 && start.y < frame.rows - 20) {
                        cv::putText(frame, std::to_string(int(x)), 
                                   cv::Point(start.x + 5, std::min((float)frame.rows - 5, start.y + 20)), 
                                   cv::FONT_HERSHEY_SIMPLEX, 0.4, cv::Scalar(209, 206, 0), 1, cv::LINE_AA);
                    }
                }
            }
        }
        
        // ğŸ”§ æ–°å¢ï¼šæ˜¾ç¤ºç½‘æ ¼ä¿¡æ¯
        std::string gridInfo = "Grid: " + std::to_string(int(gridSpacing)) + "mm, Range: " + 
                              std::to_string(int(rangeX)) + "x" + std::to_string(int(rangeY)) + "mm";
        cv::putText(frame, gridInfo, cv::Point(10, 120), cv::FONT_HERSHEY_SIMPLEX, 0.5, 
                   cv::Scalar(209, 206, 0), 1, cv::LINE_AA);
    }
    
    // æ·»åŠ æ ‡å®šçŠ¶æ€ä¿¡æ¯
    std::string statusText = "Calibration Mode: " + std::string(calibrationMode_ ? "ON" : "OFF");
    cv::putText(frame, statusText, cv::Point(10, 30), cv::FONT_HERSHEY_SIMPLEX, 0.7, cv::Scalar(0, 0, 255), 2);
    
    if (homographyMapper_.isCalibrated()) {
        cv::putText(frame, "Calibrated: YES", cv::Point(10, 60), cv::FONT_HERSHEY_SIMPLEX, 0.7, cv::Scalar(226, 43, 138), 2); // ç´«è‰² (138, 43, 226) è¡¨ç¤ºæˆåŠŸ
    } else {
        cv::putText(frame, "Calibrated: NO (Need 4+ points)", cv::Point(10, 60), cv::FONT_HERSHEY_SIMPLEX, 0.7, cv::Scalar(112, 25, 25), 2); // æ·±è“è‰² (25, 25, 112) è¡¨ç¤ºé”™è¯¯
    }
    
    cv::putText(frame, "Points: " + std::to_string(points.size()), cv::Point(10, 90), cv::FONT_HERSHEY_SIMPLEX, 0.7, cv::Scalar(255, 123, 0), 2); // è“è‰² (0, 123, 255) è¡¨ç¤ºä¿¡æ¯
}

void VideoStreamer::broadcastFrame() {
    static int frame_count = 0;  // é™æ€å¸§è®¡æ•°å™¨
    static auto lastBroadcastTime = std::chrono::steady_clock::now();
    static int skippedFrames = 0;
    
    // ä¸¥æ ¼çš„è¿æ¥æ£€æŸ¥ - åœ¨ä»»ä½•Matæ“ä½œä¹‹å‰è¿›è¡Œ
    {
        std::lock_guard<std::mutex> conn_lock(conn_mutex_);
        if (connections_.empty()) {
            return; // æ²¡æœ‰è¿æ¥æ—¶ç›´æ¥è¿”å›ï¼Œé¿å…ä¸å¿…è¦çš„å¤„ç†
        }
    }
    
    // æ£€æŸ¥è¿è¡ŒçŠ¶æ€
    if (!running_) {
        return;
    }
    
    // å¸§ç‡æ§åˆ¶é€»è¾‘
    auto currentTime = std::chrono::steady_clock::now();
    auto timeSinceLastBroadcast = std::chrono::duration_cast<std::chrono::milliseconds>(currentTime - lastBroadcastTime);
    
    // åŠ¨æ€å¸§ç‡æ§åˆ¶ï¼šæ ¹æ®è¿æ¥æ•°è°ƒæ•´
    int targetInterval;
    {
        std::lock_guard<std::mutex> conn_lock(conn_mutex_);
        if (connections_.size() <= 1) {
            targetInterval = 33; // ~30 FPS for single connection
        } else if (connections_.size() <= 2) {
            targetInterval = 40; // ~25 FPS for 2 connections
        } else {
            targetInterval = 50; // ~20 FPS for 3+ connections
        }
    }
    
    if (timeSinceLastBroadcast.count() < targetInterval) {
        skippedFrames++;
        return;
    }
    
    skippedFrames = 0;
    lastBroadcastTime = currentTime;
    
    // æ€§èƒ½ç›‘æ§ï¼šå¹¿æ’­å¼€å§‹æ—¶é—´
    auto broadcastStart = std::chrono::high_resolution_clock::now();
    
    // å†æ¬¡æ£€æŸ¥è¿æ¥çŠ¶æ€ï¼ˆåŒé‡æ£€æŸ¥ï¼‰
    {
        std::lock_guard<std::mutex> conn_lock(conn_mutex_);
        if (connections_.empty()) {
            return;
        }
    }

    cv::Mat processedFrame;
    
    // æ€§èƒ½ç›‘æ§ï¼šå¸§è·å–æ—¶é—´
    auto frameGetStart = std::chrono::high_resolution_clock::now();
    
    // æ ¹æ®æ¨¡å¼é€‰æ‹©åˆé€‚çš„å¸§åˆ†è¾¨ç‡ - æ·»åŠ å¼‚å¸¸å¤„ç†
    try {
        if (cameraCalibrationMode_) {
            // ç›¸æœºæ ‡å®šæ¨¡å¼ï¼šä½¿ç”¨ä¼˜åŒ–çš„æ˜¾ç¤ºå¸§ï¼ˆå·²åŒ…å«è§’ç‚¹ç»˜åˆ¶ï¼‰
            processedFrame = getDisplayFrame();
            if (processedFrame.empty()) {
                std::cerr << "Warning: getDisplayFrame() returned empty frame in calibration mode" << std::endl;
                return;
            }
        } else {
            // æ™®é€šæ¨¡å¼ï¼šä½¿ç”¨åŸå§‹å¸§ - æ·»åŠ æ›´ä¸¥æ ¼çš„æ£€æŸ¥
            std::lock_guard<std::mutex> lock(mutex_);
            if (frame_.empty() || frame_.cols <= 0 || frame_.rows <= 0) {
                std::cerr << "Warning: frame_ is empty or invalid in normal mode" << std::endl;
                return;
            }
            
            // éªŒè¯Matå¯¹è±¡çš„æœ‰æ•ˆæ€§
            if (frame_.type() != CV_8UC3 && frame_.type() != CV_8UC1) {
                std::cerr << "Warning: frame_ has invalid type: " << frame_.type() << std::endl;
                return;
            }
            
            processedFrame = frame_.clone();
            if (processedFrame.empty()) {
                std::cerr << "Warning: frame_.clone() failed" << std::endl;
                return;
            }
        }
    } catch (const cv::Exception& e) {
        std::cerr << "OpenCV error in frame acquisition: " << e.what() << std::endl;
        return;
    } catch (const std::exception& e) {
        std::cerr << "Error in frame acquisition: " << e.what() << std::endl;
        return;
    }
    
    auto frameGetEnd = std::chrono::high_resolution_clock::now();
    double frameGetTime = std::chrono::duration<double, std::milli>(frameGetEnd - frameGetStart).count();
    
    // éªŒè¯å¸§æ•°æ®å®Œæ•´æ€§ - æ›´ä¸¥æ ¼çš„æ£€æŸ¥
    if (processedFrame.empty() || processedFrame.cols <= 0 || processedFrame.rows <= 0) {
        std::cerr << "Warning: Invalid frame data after acquisition, skipping broadcast" << std::endl;
        return;
    }
    
    // éªŒè¯Matå¯¹è±¡çš„è¿ç»­æ€§å’Œç±»å‹
    if (!processedFrame.isContinuous()) {
        try {
            processedFrame = processedFrame.clone();
        } catch (const cv::Exception& e) {
            std::cerr << "OpenCV error making frame continuous: " << e.what() << std::endl;
            return;
        }
    }
    
    // æ€§èƒ½ç›‘æ§ï¼šå¤„ç†æ—¶é—´
    auto processingStart = std::chrono::high_resolution_clock::now();
    
    // å¦‚æœåœ¨æ ‡å®šæ¨¡å¼ä¸‹ï¼Œç»˜åˆ¶æ ‡å®šç‚¹ - æ·»åŠ å¼‚å¸¸å¤„ç†
    try {
        if (calibrationMode_) {
            drawCalibrationPoints(processedFrame);
        }
        
        // å¦‚æœåœ¨ArUcoæ¨¡å¼ä¸‹ï¼Œæ£€æµ‹å¹¶ç»˜åˆ¶ArUcoæ ‡è®°
        if (arucoMode_) {
            detectArUcoMarkers(processedFrame);
        }
    } catch (const cv::Exception& e) {
        std::cerr << "OpenCV error in frame processing: " << e.what() << std::endl;
        return;
    } catch (const std::exception& e) {
        std::cerr << "Error in frame processing: " << e.what() << std::endl;
        return;
    }
    
    auto processingEnd = std::chrono::high_resolution_clock::now();
    double processingTime = std::chrono::duration<double, std::milli>(processingEnd - processingStart).count();
    
    // åœ¨ç¼–ç å‰è¿›ä¸€æ­¥éªŒè¯å¸§çš„æœ‰æ•ˆæ€§
    if (processedFrame.type() != CV_8UC3 && processedFrame.type() != CV_8UC1) {
        std::cerr << "Warning: Invalid frame type for JPEG encoding: " << processedFrame.type() << std::endl;
        return;
    }
    
    // éªŒè¯å¸§æ˜¯å¦è¿ç»­
    if (!processedFrame.isContinuous()) {
        // å¦‚æœä¸è¿ç»­ï¼Œåˆ›å»ºä¸€ä¸ªè¿ç»­çš„å‰¯æœ¬
        try {
            processedFrame = processedFrame.clone();
        } catch (const cv::Exception& e) {
            std::cerr << "OpenCV error making frame continuous for encoding: " << e.what() << std::endl;
            return;
        }
    }
    
    // æ€§èƒ½ç›‘æ§ï¼šJPEGç¼–ç æ—¶é—´
    auto encodeStart = std::chrono::high_resolution_clock::now();
    
    // å°†å¸§ç¼–ç ä¸ºJPEGï¼Œä½¿ç”¨ä¼˜åŒ–çš„å‚æ•°å‡å°‘ç¼–ç æ—¶é—´
    std::vector<uchar> buf;
    
    // å±€åŸŸç½‘ç¯å¢ƒä¼˜åŒ–ï¼šä½¿ç”¨æ›´é«˜çš„JPEGè´¨é‡ï¼Œç¡®ä¿å›¾åƒæ¸…æ™°åº¦
    int jpegQuality = 92;  // å±€åŸŸç½‘ç¯å¢ƒä½¿ç”¨é«˜è´¨é‡
    bool fastMode = false;
    
    // æ£€æŸ¥æ˜¯å¦éœ€è¦å¯ç”¨å¿«é€Ÿæ¨¡å¼ï¼ˆä»…åœ¨æç«¯æƒ…å†µä¸‹ï¼‰
    static auto lastOverrunTime = std::chrono::steady_clock::now();
    static int overrunCount = 0;
    
    auto now = std::chrono::steady_clock::now();
    if (std::chrono::duration_cast<std::chrono::seconds>(now - lastOverrunTime).count() < 5) {
        overrunCount++;
        if (overrunCount > 5) { // æé«˜é˜ˆå€¼ï¼š5ç§’å†…è¶…è¿‡5æ¬¡è¶…æ—¶æ‰å¯ç”¨å¿«é€Ÿæ¨¡å¼
            fastMode = true;
            jpegQuality = 75;  // å³ä½¿åœ¨å¿«é€Ÿæ¨¡å¼ä¸‹ä¹Ÿä¿æŒè¾ƒé«˜è´¨é‡
        }
    } else {
        overrunCount = 0;
        lastOverrunTime = now;
    }
    
    // æ ¹æ®è¿æ¥æ•°è½»å¾®è°ƒæ•´è´¨é‡ï¼ˆå±€åŸŸç½‘ç¯å¢ƒä¸‹å½±å“è¾ƒå°ï¼‰
    if (connections_.size() > 2) {
        jpegQuality = std::max(80, jpegQuality - 5 * (int)(connections_.size() - 2));
    }
    
    std::vector<int> encode_params = {
        cv::IMWRITE_JPEG_QUALITY, jpegQuality,
        cv::IMWRITE_JPEG_OPTIMIZE, fastMode ? 0 : 1,  // å¿«é€Ÿæ¨¡å¼ç¦ç”¨ä¼˜åŒ–
        cv::IMWRITE_JPEG_PROGRESSIVE, 0  // ç¦ç”¨æ¸è¿›å¼JPEGä»¥åŠ å¿«ç¼–ç 
    };
    
    // ä¿æŒåŒåˆ†è¾¨ç‡è®¾è®¡ï¼šç›´æ¥ä½¿ç”¨å¤„ç†åçš„å¸§è¿›è¡Œç¼–ç 
    // å±€åŸŸç½‘ç¯å¢ƒä¸‹ä¸éœ€è¦é¢å¤–é™é‡‡æ ·
    cv::Mat encodeFrame = processedFrame;
    
    bool encode_success = false;
    try {
        encode_success = cv::imencode(".jpg", encodeFrame, buf, encode_params);
    } catch (const cv::Exception& e) {
        std::cerr << "OpenCV error in JPEG encoding: " << e.what() << std::endl;
        return;
    } catch (const std::exception& e) {
        std::cerr << "Error in JPEG encoding: " << e.what() << std::endl;
        return;
    }
    
    auto encodeEnd = std::chrono::high_resolution_clock::now();
    double encodeTime = std::chrono::duration<double, std::milli>(encodeEnd - encodeStart).count();
    
    // æ£€æŸ¥ç¼–ç æ˜¯å¦æˆåŠŸ
    if (!encode_success || buf.empty()) {
        std::cerr << "Warning: JPEG encoding failed, skipping frame transmission" << std::endl;
        return;
    }
    
    // éªŒè¯ç¼–ç ç»“æœçš„å¤§å°åˆç†æ€§
    if (buf.size() < 100 || buf.size() > 1024 * 1024) {  // 100å­—èŠ‚åˆ°1MBä¹‹é—´
        std::cerr << "Warning: JPEG encoded size abnormal (" << buf.size() 
                  << " bytes), skipping frame transmission" << std::endl;
        return;
    }
    
    // æ€§èƒ½ç›‘æ§ï¼šç½‘ç»œä¼ è¾“æ—¶é—´
    auto networkStart = std::chrono::high_resolution_clock::now();
    
    // æ¯100å¸§å‘é€ä¸€æ¬¡åˆ†è¾¨ç‡ä¿¡æ¯
    if (frame_count % 100 == 0) {
        // æ„å»ºå¸§ä¿¡æ¯æ¶ˆæ¯
        std::string info_message = std::string("{\"type\":\"frame_info\",\"width\":")
                              + std::to_string(processedFrame.cols) + ",\"height\":"
                              + std::to_string(processedFrame.rows) + "}";
        
        // å¹¿æ’­å¸§ä¿¡æ¯
        std::lock_guard<std::mutex> conn_lock(conn_mutex_);
        for (auto conn : connections_) {
            if (conn) {
                try {
                    conn->send_text(info_message);
                } catch (const std::exception& e) {
                    std::cerr << "Error sending frame info: " << e.what() << std::endl;
                }
            }
        }
    }
    
    // å¹¿æ’­å¸§æ•°æ® - æ·»åŠ å¼‚å¸¸å¤„ç†
    {
        std::lock_guard<std::mutex> lock(conn_mutex_);
        for (auto conn : connections_) {
            if (conn) {
                try {
                    conn->send_binary(std::string(buf.begin(), buf.end()));
                } catch (const std::exception& e) {
                    std::cerr << "Error sending frame data: " << e.what() << std::endl;
                }
            }
        }
    }
    
    auto networkEnd = std::chrono::high_resolution_clock::now();
    double networkTime = std::chrono::duration<double, std::milli>(networkEnd - networkStart).count();
    
    // æ€»ä½“å¹¿æ’­æ—¶é—´
    auto broadcastEnd = std::chrono::high_resolution_clock::now();
    double totalBroadcastTime = std::chrono::duration<double, std::milli>(broadcastEnd - broadcastStart).count();
    
    frame_count++;
    
    // æ€§èƒ½æŠ¥å‘Šï¼ˆæ¯5ç§’è¾“å‡ºä¸€æ¬¡è¯¦ç»†åˆ†æï¼‰
    static auto lastDetailedReport = std::chrono::steady_clock::now();
    static double totalFrameGetTime = 0, totalProcessingTime = 0, totalEncodeTime = 0, totalNetworkTime = 0, cumulativeBroadcastTime = 0;
    static int reportFrameCount = 0;
    
    totalFrameGetTime += frameGetTime;
    totalProcessingTime += processingTime;
    totalEncodeTime += encodeTime;
    totalNetworkTime += networkTime;
    cumulativeBroadcastTime += totalBroadcastTime;
    reportFrameCount++;
    
    auto reportNow = std::chrono::steady_clock::now();
    if (std::chrono::duration_cast<std::chrono::seconds>(reportNow - lastDetailedReport).count() >= 5) {
        double avgFrameGet = totalFrameGetTime / reportFrameCount;
        double avgProcessing = totalProcessingTime / reportFrameCount;
        double avgEncode = totalEncodeTime / reportFrameCount;
        double avgNetwork = totalNetworkTime / reportFrameCount;
        double avgTotal = cumulativeBroadcastTime / reportFrameCount;
        
        std::cout << "ğŸ“Š [BROADCAST PERFORMANCE] Average times (ms):" << std::endl;
        std::cout << "  ğŸ“¥ Frame Get: " << std::fixed << std::setprecision(2) << avgFrameGet << "ms" << std::endl;
        std::cout << "  ğŸ”§ Processing: " << avgProcessing << "ms" << std::endl;
        std::cout << "  ğŸ“· JPEG Encode: " << avgEncode << "ms" << std::endl;
        std::cout << "  ğŸŒ Network Send: " << avgNetwork << "ms" << std::endl;
        std::cout << "  ğŸ“¡ Total Broadcast: " << avgTotal << "ms" << std::endl;
        std::cout << "  ğŸ”„ Theoretical FPS: " << (1000.0 / avgTotal) << std::endl;
        std::cout << "  ğŸ“¦ Avg JPEG Size: " << (buf.size() / 1024) << "KB" << std::endl;
        std::cout << "  ğŸ”— Connections: " << connections_.size() << std::endl;
        
        // é‡ç½®è®¡æ•°å™¨
        totalFrameGetTime = totalProcessingTime = totalEncodeTime = totalNetworkTime = cumulativeBroadcastTime = 0;
        reportFrameCount = 0;
        lastDetailedReport = reportNow;
    }
}

bool VideoStreamer::getFrame(cv::Mat& frame) {
    std::lock_guard<std::mutex> lock(mutex_);
    if (frame_.empty()) {
        return false;
    }
    
    frame = frame_.clone();
    return true;
}

void VideoStreamer::captureThread() {
    cv::Mat frame;
    
    // æ€§èƒ½ç›‘æ§å˜é‡
    auto lastPerformanceReport = std::chrono::steady_clock::now();
    int frameProcessedCount = 0;
    double totalProcessingTime = 0.0;
    
    while (running_) {
        auto frameStart = std::chrono::high_resolution_clock::now();
        
        if (cap_.read(frame)) {
            // æˆåŠŸè¯»å–å¸§ï¼Œé‡ç½®å¤±è´¥è®¡æ•°å™¨
            if (frameReadFailureCount_ > 0) {
                std::cout << "ğŸ“¹ [CAMERA RECOVERY] æ‘„åƒå¤´æ¢å¤æ­£å¸¸ï¼Œé‡ç½®å¤±è´¥è®¡æ•°å™¨" << std::endl;
                frameReadFailureCount_ = 0;
                sendErrorNotification("camera_recovery", "camera_recovered", "device_working_normally");
            }
            
            if (frame.empty()) {
                cerr << "Error: Empty frame received" << endl;
                continue;
            }
            
            // éªŒè¯å¸§æ•°æ®å®Œæ•´æ€§
            if (frame.cols <= 0 || frame.rows <= 0) {
                cerr << "Error: Invalid frame dimensions" << endl;
                continue;
            }
            
            // åˆ›å»ºå¤„ç†å¸§çš„å‰¯æœ¬ï¼Œé¿å…ä¿®æ”¹åŸå§‹å¸§
            cv::Mat processedFrame = frame.clone();
            
            // æ€§èƒ½ä¼˜åŒ–ï¼šåªåœ¨ç›¸æœºæ ¡æ­£å¯ç”¨ä¸”å·²æ ‡å®šæ—¶æ‰è¿›è¡Œç•¸å˜æ ¡æ­£
            // å¹¶ä¸”ä¸åœ¨æ ‡å®šæ¨¡å¼ä¸‹è¿›è¡Œæ ¡æ­£ï¼ˆæ ‡å®šéœ€è¦åŸå§‹ç•¸å˜å›¾åƒï¼‰
            if (isCameraCalibrated() && cameraCorrectionEnabled_ && !cameraCalibrationMode_) {
                try {
                    auto undistortStart = std::chrono::high_resolution_clock::now();
                    
                    cv::Mat undistortedFrame = cameraCalibrator_.undistortImage(processedFrame);
                    
                    auto undistortEnd = std::chrono::high_resolution_clock::now();
                    double undistortTime = std::chrono::duration<double, std::milli>(undistortEnd - undistortStart).count();
                    
                    // éªŒè¯å»ç•¸å˜ç»“æœæ˜¯å¦æœ‰æ•ˆ
                    if (!undistortedFrame.empty() && 
                        undistortedFrame.cols == processedFrame.cols && 
                        undistortedFrame.rows == processedFrame.rows) {
                        processedFrame = undistortedFrame;
                        
                        // æ€§èƒ½æ—¥å¿—ï¼ˆæ¯10ç§’è¾“å‡ºä¸€æ¬¡ï¼‰
                        static auto lastUndistortLog = std::chrono::steady_clock::now();
                        auto undistortLogTime = std::chrono::steady_clock::now();
                        if (std::chrono::duration_cast<std::chrono::seconds>(undistortLogTime - lastUndistortLog).count() >= 10) {
                            std::cout << "ğŸ“Š [PERFORMANCE] Undistortion time: " << undistortTime << "ms" << std::endl;
                            lastUndistortLog = undistortLogTime;
                        }
                    } else {
                        cerr << "Warning: Undistortion returned invalid result, using original frame" << endl;
                    }
                } catch (const cv::Exception& e) {
                    cerr << "OpenCV error in undistortion: " << e.what() << endl;
                    // ç»§ç»­ä½¿ç”¨åŸå§‹å¸§ï¼Œä¸è¿›è¡Œå»ç•¸å˜
                } catch (const std::exception& e) {
                    cerr << "Error in undistortion: " << e.what() << endl;
                    // ç»§ç»­ä½¿ç”¨åŸå§‹å¸§ï¼Œä¸è¿›è¡Œå»ç•¸å˜
                }
            }
            
            // å¦‚æœå¤„äºç›¸æœºæ ‡å®šæ¨¡å¼ï¼Œä½¿ç”¨è½»é‡çº§æ˜¾ç¤ºå¤„ç†
            if (cameraCalibrationMode_) {
                try {
                    // æ€§èƒ½ä¼˜åŒ–ï¼šé™ä½æ ‡å®šæ¨¡å¼ä¸‹çš„æ£€æµ‹é¢‘ç‡
                    static int detectionCounter = 0;
                    detectionCounter++;
                    
                    // æ¯3å¸§æ‰è¿›è¡Œä¸€æ¬¡è§’ç‚¹æ£€æµ‹ï¼Œå‡å°‘CPUè´Ÿè½½
                    if (detectionCounter % 3 == 0) {
                        // å¯¹æ˜¾ç¤ºåˆ†è¾¨ç‡çš„å¸§è¿›è¡Œè½»é‡çº§å¤„ç†
                        cv::Mat displayFrame;
                        if (processedFrame.cols != displayWidth_ || processedFrame.rows != displayHeight_) {
                            cv::resize(processedFrame, displayFrame, cv::Size(displayWidth_, displayHeight_));
                        } else {
                            displayFrame = processedFrame.clone();
                        }
                        
                        // åªåœ¨æ˜¾ç¤ºå¸§ä¸Šåšç®€å•çš„æ£‹ç›˜æ ¼æ£€æµ‹å’Œç»˜åˆ¶ï¼ˆä½ç²¾åº¦ï¼Œå¿«é€Ÿï¼‰
                        std::vector<cv::Point2f> corners;
                        bool found = false;
                        
                        // ä½¿ç”¨æ›´å®½æ¾çš„æ£€æµ‹æ¡ä»¶è¿›è¡Œå¿«é€Ÿæ£€æµ‹
                        int quickFlags = cv::CALIB_CB_ADAPTIVE_THRESH;
                        found = cv::findChessboardCorners(displayFrame, cameraCalibrator_.getBoardSize(), corners, quickFlags);
                        
                        if (found) {
                            // ç¼©æ”¾è§’ç‚¹åæ ‡å›åŸå§‹å¸§æ¯”ä¾‹ï¼ˆç”¨äºç²¾ç¡®æ˜¾ç¤ºï¼‰
                            float scaleX = (float)processedFrame.cols / displayWidth_;
                            float scaleY = (float)processedFrame.rows / displayHeight_;
                            for (auto& corner : corners) {
                                corner.x *= scaleX;
                                corner.y *= scaleY;
                            }
                            
                            cv::drawChessboardCorners(processedFrame, cameraCalibrator_.getBoardSize(), corners, found);
                            cv::putText(processedFrame, "Chessboard OK", cv::Point(processedFrame.cols - 160, 30),
                                      cv::FONT_HERSHEY_SIMPLEX, 0.6, cv::Scalar(226, 43, 138), 2, cv::LINE_AA); // ç´«è‰² (138, 43, 226) è¡¨ç¤ºæˆåŠŸ
                        } else {
                            cv::putText(processedFrame, "Searching...", cv::Point(processedFrame.cols - 150, 30),
                                      cv::FONT_HERSHEY_SIMPLEX, 0.6, cv::Scalar(0, 100, 255), 2, cv::LINE_AA);
                        }
                    }
                    
                    // æ˜¾ç¤ºå½“å‰æ ¡æ­£çŠ¶æ€
                    if (cameraCorrectionEnabled_ && isCameraCalibrated()) {
                        cv::putText(processedFrame, "Correction: OFF (Calibration Mode)", cv::Point(10, processedFrame.rows - 20),
                                  cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(255, 165, 0), 1, cv::LINE_AA);
                    }
                    
                } catch (const std::exception& e) {
                    cerr << "Error in chessboard visualization: " << e.what() << endl;
                }
            } else if (calibrationMode_) {
                // åæ ‡å˜æ¢æ ‡å®šæ¨¡å¼çš„ç®€æ´æç¤º
                                    cv::putText(processedFrame, "Click to add point", cv::Point(processedFrame.cols - 180, 30),
                          cv::FONT_HERSHEY_SIMPLEX, 0.6, cv::Scalar(0, 149, 255), 2, cv::LINE_AA); // æ©™è‰² (255, 149, 0) è¡¨ç¤ºæç¤º
            } else {
                // æ­£å¸¸æ¨¡å¼ï¼šæ˜¾ç¤ºæ ¡æ­£çŠ¶æ€
                if (isCameraCalibrated() && cameraCorrectionEnabled_) {
                    cv::putText(processedFrame, "Correction: ON", cv::Point(10, processedFrame.rows - 20),
                              cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(226, 43, 138), 1, cv::LINE_AA); // ç´«è‰² (138, 43, 226) è¡¨ç¤ºæˆåŠŸ
                } else if (isCameraCalibrated()) {
                    cv::putText(processedFrame, "Correction: OFF", cv::Point(10, processedFrame.rows - 20),
                              cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(112, 25, 25), 1, cv::LINE_AA); // æ·±è“è‰² (25, 25, 112) è¡¨ç¤ºé”™è¯¯
                }
            }
            
            // åŒæµç­–ç•¥ï¼šå¼ºåŒ–å®‰å…¨çš„Matæ“ä½œ
            {
                std::lock_guard<std::mutex> lock(mutex_);
                
                // éªŒè¯processedFrameçš„æœ‰æ•ˆæ€§
                if (processedFrame.empty() || processedFrame.cols <= 0 || processedFrame.rows <= 0) {
                    std::cerr << "Warning: Invalid processedFrame, skipping frame update" << std::endl;
                    continue;
                }
                
                try {
                    // å®‰å…¨çš„å¤åˆ¶ç­–ç•¥ï¼šç¡®ä¿Matå¯¹è±¡å®Œæ•´æ€§
                    frame_ = processedFrame.clone();           // æ·±åº¦å¤åˆ¶ï¼Œé¿å…moveåçš„ç©ºå¯¹è±¡
                    detectionFrame_ = processedFrame.clone();  // ç‹¬ç«‹å¤åˆ¶ï¼Œç¡®ä¿ä¸¤ä¸ªå¯¹è±¡éƒ½æœ‰æ•ˆ
                    
                    // éªŒè¯å¤åˆ¶ç»“æœ
                    if (frame_.empty() || detectionFrame_.empty()) {
                        std::cerr << "Error: Frame copy operation failed" << std::endl;
                        continue;
                    }
                    
                } catch (const cv::Exception& e) {
                    std::cerr << "OpenCV error in frame copying: " << e.what() << std::endl;
                    continue;
                } catch (const std::exception& e) {
                    std::cerr << "Error in frame copying: " << e.what() << std::endl;
                    continue;
                }
            }
            
            // æ€§èƒ½ç›‘æ§
            auto frameEnd = std::chrono::high_resolution_clock::now();
            double frameTime = std::chrono::duration<double, std::milli>(frameEnd - frameStart).count();
            totalProcessingTime += frameTime;
            frameProcessedCount++;
            
            // æ¯10ç§’è¾“å‡ºä¸€æ¬¡æ€§èƒ½æŠ¥å‘Š
            auto frameReportTime = std::chrono::steady_clock::now();
            if (std::chrono::duration_cast<std::chrono::seconds>(frameReportTime - lastPerformanceReport).count() >= 10) {
                double avgProcessingTime = totalProcessingTime / frameProcessedCount;
                double theoreticalFPS = 1000.0 / avgProcessingTime;
                
                std::cout << "ğŸ“Š [PERFORMANCE] Avg frame processing: " << avgProcessingTime << "ms, "
                          << "Theoretical FPS: " << theoreticalFPS << ", "
                          << "Correction: " << (cameraCorrectionEnabled_ ? "ON" : "OFF") << ", "
                          << "Calibration mode: " << (cameraCalibrationMode_ ? "ON" : "OFF") << std::endl;
                
                // æ·»åŠ ç³»ç»Ÿèµ„æºä¿¡æ¯
                std::cout << "ğŸ–¥ï¸ [SYSTEM RESOURCES]\n" << getSystemResourceInfo() << std::endl;
                
                // é‡ç½®è®¡æ•°å™¨
                totalProcessingTime = 0.0;
                frameProcessedCount = 0;
                lastPerformanceReport = frameReportTime;
            }
            
        } else {
            // å¸§è¯»å–å¤±è´¥å¤„ç†
            frameReadFailureCount_++;
            cerr << "Error: Failed to read frame (count: " << frameReadFailureCount_ << ")" << endl;
            
            // æ£€æµ‹è¿ç»­å¤±è´¥æƒ…å†µå¹¶é€šçŸ¥å‰ç«¯
            if (frameReadFailureCount_ >= 5) {
                // è¿ç»­5æ¬¡å¤±è´¥ï¼Œå‘é€è­¦å‘Š
                sendErrorNotification("camera_warning", "æ‘„åƒå¤´è¯»å–ä¸ç¨³å®š", 
                                    "è¿ç»­" + std::to_string(frameReadFailureCount_) + "æ¬¡å¸§è¯»å–å¤±è´¥");
            }
            
            if (frameReadFailureCount_ >= 20) {
                // è¿ç»­20æ¬¡å¤±è´¥ï¼Œå‘é€ä¸¥é‡é”™è¯¯
                sendErrorNotification("camera_critical", "æ‘„åƒå¤´è®¾å¤‡å¼‚å¸¸", 
                                    "è®¾å¤‡å¯èƒ½è¢«å ç”¨æˆ–æ–­å¼€è¿æ¥ï¼Œè¯·æ£€æŸ¥æ‘„åƒå¤´çŠ¶æ€");
                
                // å°è¯•é‡æ–°åˆå§‹åŒ–æ‘„åƒå¤´
                attemptCameraRecovery();
            }
            
            this_thread::sleep_for(chrono::milliseconds(100));
        }
    }
}

// ç›¸æœºæ ‡å®šç›¸å…³æ–¹æ³•å®ç°
bool VideoStreamer::isCameraCalibrationMode() const {
    return cameraCalibrationMode_;
}

void VideoStreamer::setCameraCalibrationMode(bool mode) {
    cameraCalibrationMode_ = mode;
}

bool VideoStreamer::addCameraCalibrationImage() {
    // ä½¿ç”¨é«˜åˆ†è¾¨ç‡æ£€æµ‹å¸§è¿›è¡Œæ ‡å®š
    cv::Mat detectionFrame;
    
    try {
        detectionFrame = getDetectionFrame();
        
        if (detectionFrame.empty()) {
            std::cerr << "No detection frame available for calibration" << std::endl;
            return false;
        }
        
        // é¢å¤–çš„æœ‰æ•ˆæ€§æ£€æŸ¥
        if (detectionFrame.cols <= 0 || detectionFrame.rows <= 0) {
            std::cerr << "Invalid detection frame dimensions for calibration" << std::endl;
            return false;
        }
        
        // æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        if (detectionFrame.type() != CV_8UC3 && detectionFrame.type() != CV_8UC1) {
            std::cerr << "Invalid detection frame type for calibration: " << detectionFrame.type() << std::endl;
            return false;
        }
        
        return cameraCalibrator_.addCalibrationImage(detectionFrame);
        
    } catch (const cv::Exception& e) {
        std::cerr << "OpenCV error in addCameraCalibrationImage: " << e.what() << std::endl;
        return false;
    } catch (const std::exception& e) {
        std::cerr << "Error in addCameraCalibrationImage: " << e.what() << std::endl;
        return false;
    }
}

bool VideoStreamer::calibrateCamera() {
    return cameraCalibrator_.calibrate();
}

bool VideoStreamer::saveCameraCalibrationData(const std::string& filename) {
    std::string filepath = filename.empty() ? cameraCalibrationFilePath_ : filename;
    return cameraCalibrator_.saveCalibrationData(filepath);
}

bool VideoStreamer::loadCameraCalibrationData(const std::string& filename) {
    std::string filepath = filename.empty() ? cameraCalibrationFilePath_ : filename;
    return cameraCalibrator_.loadCalibrationData(filepath);
}

cv::Mat VideoStreamer::getCameraMatrix() const {
    return cameraCalibrator_.getCameraMatrix();
}

cv::Mat VideoStreamer::getDistCoeffs() const {
    return cameraCalibrator_.getDistCoeffs();
}

bool VideoStreamer::getCameraCalibrationMatrices(cv::Mat& cameraMatrix, cv::Mat& distCoeffs) const {
    if (!isCameraCalibrated()) {
        return false;
    }
    
    cameraMatrix = getCameraMatrix();
    distCoeffs = getDistCoeffs();
    
    return !cameraMatrix.empty() && !distCoeffs.empty();
}

double VideoStreamer::getCalibrationError() const {
    return cameraCalibrator_.getCalibrationError();
}

size_t VideoStreamer::getCalibrationImageCount() const {
    return cameraCalibrator_.getImageCount();
}

void VideoStreamer::setChessboardSize(int width, int height) {
    cameraCalibrator_.setChessboardSize(width, height);
}

void VideoStreamer::setSquareSize(float size) {
    cameraCalibrator_.setSquareSize(size);
}

void VideoStreamer::setBlurKernelSize(int size) {
    cameraCalibrator_.setBlurKernelSize(size);
}

void VideoStreamer::setQualityCheckLevel(int level) {
    CameraCalibrator::QualityCheckLevel qualityLevel;
    switch (level) {
        case 0: qualityLevel = CameraCalibrator::STRICT; break;
        case 1: qualityLevel = CameraCalibrator::BALANCED; break;
        case 2: qualityLevel = CameraCalibrator::PERMISSIVE; break;
        default: qualityLevel = CameraCalibrator::BALANCED; break;
    }
    cameraCalibrator_.setQualityCheckLevel(qualityLevel);
}

int VideoStreamer::getBlurKernelSize() const {
    return cameraCalibrator_.getBlurKernelSize();
}

bool VideoStreamer::isCameraCalibrated() const {
    return cameraCalibrator_.isCalibrated();
}

// æ–°å¢ï¼šç›¸æœºæ ‡å®šä¼šè¯ç®¡ç†æ–¹æ³•å®ç°
void VideoStreamer::startNewCameraCalibrationSession() {
    std::cout << "VideoStreamer: Starting new camera calibration session" << std::endl;
    cameraCalibrator_.startNewCalibrationSession();
    
    // å‘é€ä¼šè¯çŠ¶æ€æ›´æ–°åˆ°å®¢æˆ·ç«¯
    std::string response = "{\"type\":\"camera_calibration_session_started\","
                          "\"message\":\"New calibration session started\","
                          "\"image_count\":0}";
    
    // å¹¿æ’­åˆ°æ‰€æœ‰è¿æ¥çš„å®¢æˆ·ç«¯
    std::lock_guard<std::mutex> lock(conn_mutex_);
    for (auto& conn : connections_) {
        try {
            conn->send_text(response);
        } catch (const std::exception& e) {
            std::cerr << "Error sending session start notification: " << e.what() << std::endl;
        }
    }
}

void VideoStreamer::clearCurrentCameraCalibrationSession() {
    std::cout << "VideoStreamer: Clearing current camera calibration session" << std::endl;
    cameraCalibrator_.clearCurrentSession();
    
    // å‘é€ä¼šè¯æ¸…é™¤é€šçŸ¥åˆ°å®¢æˆ·ç«¯
    std::string response = "{\"type\":\"camera_calibration_session_cleared\","
                          "\"message\":\"Current session cleared\","
                          "\"image_count\":0}";
    
    // å¹¿æ’­åˆ°æ‰€æœ‰è¿æ¥çš„å®¢æˆ·ç«¯
    std::lock_guard<std::mutex> lock(conn_mutex_);
    for (auto& conn : connections_) {
        try {
            conn->send_text(response);
        } catch (const std::exception& e) {
            std::cerr << "Error sending session clear notification: " << e.what() << std::endl;
        }
    }
}

size_t VideoStreamer::getCurrentSessionImageCount() const {
    return cameraCalibrator_.getCurrentSessionImageCount();
}

bool VideoStreamer::startAutoCalibrationCapture(int durationSeconds, int intervalMs) {
    // å¦‚æœå·²ç»åœ¨è‡ªåŠ¨é‡‡é›†ä¸­ï¼Œè¿”å›false
    if (autoCapturing_) {
        std::cerr << "Auto calibration capture already running" << std::endl;
        return false;
    }
    
    // å¦‚æœä¸åœ¨ç›¸æœºæ ‡å®šæ¨¡å¼ï¼Œè¿”å›false
    if (!cameraCalibrationMode_) {
        std::cerr << "Must be in camera calibration mode to start auto capture" << std::endl;
        return false;
    }
    
    // è®¾ç½®è‡ªåŠ¨é‡‡é›†æ ‡å¿—
    autoCapturing_ = true;
    
    // å¯åŠ¨è‡ªåŠ¨é‡‡é›†çº¿ç¨‹
    autoCapturingThread_ = std::thread(&VideoStreamer::autoCalibrationCaptureThread, this, durationSeconds, intervalMs);
    autoCapturingThread_.detach();
    
    std::cout << "Started auto calibration capture for " << durationSeconds << " seconds with " 
              << intervalMs << "ms interval" << std::endl;
    
    return true;
}

bool VideoStreamer::stopAutoCalibrationCapture() {
    // å¦‚æœæ²¡æœ‰åœ¨è‡ªåŠ¨é‡‡é›†ä¸­ï¼Œè¿”å›false
    if (!autoCapturing_) {
        std::cerr << "Auto calibration capture not running" << std::endl;
        return false;
    }
    
    // è®¾ç½®è‡ªåŠ¨é‡‡é›†æ ‡å¿—ä¸ºfalse
    autoCapturing_ = false;
    
    std::cout << "Stopped auto calibration capture" << std::endl;
    
    return true;
}

void VideoStreamer::autoCalibrationCaptureThread(int durationSeconds, int intervalMs) {
    // è®¡ç®—ç»“æŸæ—¶é—´
    auto endTime = std::chrono::steady_clock::now() + std::chrono::seconds(durationSeconds);
    int successCount = 0;
    int attemptCount = 0;
    
    std::cout << "=== AUTO CALIBRATION CAPTURE THREAD STARTED ===" << std::endl;
    std::cout << "Duration: " << durationSeconds << " seconds, Interval: " << intervalMs << " ms" << std::endl;
    std::cout << "Initial image count: " << cameraCalibrator_.getCurrentSessionImageCount() << std::endl;
    
    // å¾ªç¯ç›´åˆ°è¾¾åˆ°ç»“æŸæ—¶é—´æˆ–åœæ­¢æ ‡å¿—è¢«è®¾ç½®
    while (autoCapturing_ && std::chrono::steady_clock::now() < endTime) {
        // è·å–ç”¨äºæ£€æµ‹çš„é«˜åˆ†è¾¨ç‡å¸§
        cv::Mat detectionFrame = getDetectionFrame();
        
        if (!detectionFrame.empty()) {
            attemptCount++;
            std::cout << "\n--- Attempt " << attemptCount << " ---" << std::endl;
            std::cout << "Frame size: " << detectionFrame.cols << "x" << detectionFrame.rows << std::endl;
            
            // å°è¯•æ£€æµ‹æ£‹ç›˜æ ¼å¹¶æ·»åŠ æ ‡å®šå›¾åƒ
            std::vector<cv::Point2f> corners;
            bool found = cameraCalibrator_.detectChessboard(detectionFrame, corners, true);  // ä½¿ç”¨å®Œæ•´çš„è°ƒè¯•æ£€æµ‹
            
            std::cout << "Chessboard detection result: " << (found ? "SUCCESS" : "FAILED") << std::endl;
            if (found) {
                std::cout << "Detected " << corners.size() << " corners" << std::endl;
                
                // è®°å½•æ·»åŠ å‰çš„å›¾ç‰‡æ•°é‡
                size_t beforeCount = cameraCalibrator_.getCurrentSessionImageCount();
                std::cout << "Image count before adding: " << beforeCount << std::endl;
                
                // å¦‚æœæ£€æµ‹æˆåŠŸï¼Œæ·»åŠ æ ‡å®šå›¾åƒ
                bool addSuccess = cameraCalibrator_.addCalibrationImage(detectionFrame);
                
                // è®°å½•æ·»åŠ åçš„å›¾ç‰‡æ•°é‡
                size_t afterCount = cameraCalibrator_.getCurrentSessionImageCount();
                std::cout << "Add calibration image result: " << (addSuccess ? "SUCCESS" : "FAILED") << std::endl;
                std::cout << "Image count after adding: " << afterCount << std::endl;
                
                if (addSuccess) {
                    successCount++;
                    std::cout << "âœ… Successfully added calibration image " << successCount 
                              << " (attempt " << attemptCount << ")" << std::endl;
                    std::cout << "Total images in session: " << afterCount << std::endl;
                    
                    // ç«‹å³å‘æ‰€æœ‰WebSocketå®¢æˆ·ç«¯å‘é€æ›´æ–°çš„æ ‡å®šçŠ¶æ€
                    std::string status_message = std::string("{\"type\":\"camera_calibration_status\",")
                                          + "\"calibration_mode\":"
                                          + (cameraCalibrationMode_ ? "true" : "false") + ","
                                          + "\"calibrated\":"
                                          + (cameraCalibrator_.isCalibrated() ? "true" : "false") + ","
                                          + "\"image_count\":"
                                          + std::to_string(cameraCalibrator_.getImageCount()) + ","
                                          + "\"current_session_count\":"
                                          + std::to_string(cameraCalibrator_.getCurrentSessionImageCount()) + ","
                                          + "\"saved_count\":"
                                          + std::to_string(cameraCalibrator_.getImageCount()) + ","
                                          + "\"auto_capture_progress\": true}";
                    
                    std::cout << "Sending WebSocket message: " << status_message << std::endl;
                    
                    std::lock_guard<std::mutex> lock(conn_mutex_);
                    std::cout << "Number of WebSocket connections: " << connections_.size() << std::endl;
                    for (auto conn : connections_) {
                        if (conn) {
                            try {
                                conn->send_text(status_message);
                                std::cout << "Message sent to WebSocket client successfully" << std::endl;
                            } catch (const std::exception& e) {
                                std::cout << "Error sending WebSocket message: " << e.what() << std::endl;
                            }
                        }
                    }
                } else {
                    std::cout << "âŒ Failed to add calibration image (quality check failed)" << std::endl;
                }
            } else {
                std::cout << "âŒ No chessboard detected in this frame" << std::endl;
            }
        } else {
            std::cout << "âŒ Empty detection frame" << std::endl;
        }
        
        // ç­‰å¾…æŒ‡å®šçš„é—´éš”æ—¶é—´
        std::this_thread::sleep_for(std::chrono::milliseconds(intervalMs));
    }
    
    // è®¾ç½®è‡ªåŠ¨é‡‡é›†æ ‡å¿—ä¸ºfalse
    autoCapturing_ = false;
    
    std::cout << "\n=== AUTO CALIBRATION CAPTURE COMPLETED ===" << std::endl;
    std::cout << "Final results:" << std::endl;
    std::cout << "- Attempts: " << attemptCount << std::endl;
    std::cout << "- Successful captures: " << successCount << std::endl;
    std::cout << "- Final image count in session: " << cameraCalibrator_.getCurrentSessionImageCount() << std::endl;
    
    // å‘æ‰€æœ‰WebSocketå®¢æˆ·ç«¯å‘é€è‡ªåŠ¨é‡‡é›†å®Œæˆçš„æ¶ˆæ¯
    std::string completion_message = std::string("{\"type\":\"auto_capture_completed\",")
                              + "\"success_count\":"
                              + std::to_string(successCount) + ","
                              + "\"attempt_count\":"
                              + std::to_string(attemptCount) + ","
                              + "\"image_count\":"
                              + std::to_string(cameraCalibrator_.getImageCount()) + "}";
    
    std::cout << "Sending completion message: " << completion_message << std::endl;
    
    std::lock_guard<std::mutex> lock(conn_mutex_);
    for (auto conn : connections_) {
        if (conn) {
            try {
                conn->send_text(completion_message);
                std::cout << "Completion message sent to WebSocket client" << std::endl;
            } catch (const std::exception& e) {
                std::cout << "Error sending completion message: " << e.what() << std::endl;
            }
        }
    }
}

// åŒåˆ†è¾¨ç‡æ”¯æŒæ–¹æ³•
void VideoStreamer::setDisplayResolution(int width, int height) {
    displayWidth_ = width;
    displayHeight_ = height;
}

void VideoStreamer::setDetectionResolution(int width, int height) {
    detectionWidth_ = width;
    detectionHeight_ = height;
}

cv::Mat VideoStreamer::getDisplayFrame() {
    std::lock_guard<std::mutex> lock(mutex_);
    
    // å¤šé‡å®‰å…¨æ£€æŸ¥
    if (frame_.empty()) {
        return cv::Mat();
    }
    
    if (frame_.cols <= 0 || frame_.rows <= 0) {
        std::cerr << "Warning: frame_ has invalid dimensions: " 
                  << frame_.cols << "x" << frame_.rows << std::endl;
        return cv::Mat();
    }
    
    try {
        // å¦‚æœå½“å‰å¸§åˆ†è¾¨ç‡ä¸æ˜¾ç¤ºåˆ†è¾¨ç‡ä¸åŒï¼Œè¿›è¡Œç¼©æ”¾
        if (frame_.cols != displayWidth_ || frame_.rows != displayHeight_) {
            cv::Mat displayFrame;
            cv::resize(frame_, displayFrame, cv::Size(displayWidth_, displayHeight_));
            
            // éªŒè¯ç¼©æ”¾ç»“æœ
            if (displayFrame.empty()) {
                std::cerr << "Error: Frame resize operation failed" << std::endl;
                return cv::Mat();
            }
            
            return displayFrame;
        }
        
        // å®‰å…¨çš„æ·±åº¦å¤åˆ¶
        cv::Mat result = frame_.clone();
        
        // éªŒè¯å…‹éš†ç»“æœ
        if (result.empty()) {
            std::cerr << "Error: Frame clone operation failed" << std::endl;
            return cv::Mat();
        }
        
        return result;
        
    } catch (const cv::Exception& e) {
        std::cerr << "OpenCV error in getDisplayFrame: " << e.what() << std::endl;
        return cv::Mat();
    } catch (const std::exception& e) {
        std::cerr << "Error in getDisplayFrame: " << e.what() << std::endl;
        return cv::Mat();
    }
}

cv::Mat VideoStreamer::getDetectionFrame() {
    std::lock_guard<std::mutex> lock(mutex_);
    
    // å¤šé‡å®‰å…¨æ£€æŸ¥
    if (detectionFrame_.empty()) {
        std::cerr << "Warning: detectionFrame_ is empty" << std::endl;
        return cv::Mat();
    }
    
    if (detectionFrame_.cols <= 0 || detectionFrame_.rows <= 0) {
        std::cerr << "Warning: detectionFrame_ has invalid dimensions: " 
                  << detectionFrame_.cols << "x" << detectionFrame_.rows << std::endl;
        return cv::Mat();
    }
    
    try {
        // å®‰å…¨çš„æ·±åº¦å¤åˆ¶
        cv::Mat result = detectionFrame_.clone();
        
        // éªŒè¯å…‹éš†ç»“æœ
        if (result.empty() || result.cols <= 0 || result.rows <= 0) {
            std::cerr << "Error: Frame clone operation failed" << std::endl;
            return cv::Mat();
        }
        
        return result;
        
    } catch (const cv::Exception& e) {
        std::cerr << "OpenCV error in getDetectionFrame: " << e.what() << std::endl;
        return cv::Mat();
    } catch (const std::exception& e) {
        std::cerr << "Error in getDetectionFrame: " << e.what() << std::endl;
        return cv::Mat();
    }
}

// ç›¸æœºæ ¡æ­£æ§åˆ¶æ–¹æ³•
void VideoStreamer::setCameraCorrectionEnabled(bool enabled) {
    cameraCorrectionEnabled_ = enabled;
    std::cout << "ğŸ“¸ [CAMERA CORRECTION] Set to: " << (enabled ? "enabled" : "disabled") << std::endl;
}

bool VideoStreamer::isCameraCorrectionEnabled() const {
    return cameraCorrectionEnabled_;
}

// æ·»åŠ ç³»ç»Ÿèµ„æºç›‘æ§å‡½æ•°
std::string VideoStreamer::getSystemResourceInfo() {
    std::ostringstream info;
    
    try {
        // CPUä½¿ç”¨ç‡ï¼ˆé€šè¿‡è¯»å–/proc/statï¼‰
        std::ifstream cpuFile("/proc/stat");
        if (cpuFile.is_open()) {
            std::string line;
            std::getline(cpuFile, line);
            // ç®€åŒ–ç‰ˆæœ¬ï¼Œåªè·å–ç¬¬ä¸€è¡ŒCPUæ€»ä½“ä¿¡æ¯
            info << "ğŸ’» CPU: " << line.substr(0, 50) << "...\n";
            cpuFile.close();
        }
        
        // å†…å­˜ä½¿ç”¨ç‡ï¼ˆé€šè¿‡è¯»å–/proc/meminfoï¼‰
        std::ifstream memFile("/proc/meminfo");
        if (memFile.is_open()) {
            std::string line;
            long totalMem = 0, availMem = 0;
            while (std::getline(memFile, line)) {
                if (line.find("MemTotal:") == 0) {
                    sscanf(line.c_str(), "MemTotal: %ld kB", &totalMem);
                } else if (line.find("MemAvailable:") == 0) {
                    sscanf(line.c_str(), "MemAvailable: %ld kB", &availMem);
                }
                if (totalMem > 0 && availMem > 0) break;
            }
            memFile.close();
            
            if (totalMem > 0 && availMem > 0) {
                long usedMem = totalMem - availMem;
                double usagePercent = (double)usedMem / totalMem * 100;
                info << "ğŸ§  Memory: " << (usedMem/1024) << "MB/" << (totalMem/1024) 
                     << "MB (" << std::fixed << std::setprecision(1) << usagePercent << "%)\n";
            }
        }
        
        // GPUä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        std::ifstream gpuFile("/sys/class/drm/card0/device/gpu_busy_percent");
        if (gpuFile.is_open()) {
            int gpuUsage;
            gpuFile >> gpuUsage;
            info << "ğŸ® GPU: " << gpuUsage << "%\n";
            gpuFile.close();
        }
        
        // ç½‘ç»œç»Ÿè®¡ï¼ˆé€šè¿‡è¯»å–/proc/net/devï¼‰
        std::ifstream netFile("/proc/net/dev");
        if (netFile.is_open()) {
            std::string line;
            // è·³è¿‡å‰ä¸¤è¡Œæ ‡é¢˜
            std::getline(netFile, line);
            std::getline(netFile, line);
            
            while (std::getline(netFile, line)) {
                if (line.find("wlan0:") != std::string::npos || 
                    line.find("eth0:") != std::string::npos ||
                    line.find("enp") != std::string::npos) {
                    // æå–ç½‘ç»œæ¥å£ç»Ÿè®¡ä¿¡æ¯
                    info << "ğŸŒ Network: " << line.substr(0, 60) << "...\n";
                    break;
                }
            }
            netFile.close();
        }
        
    } catch (const std::exception& e) {
        info << "âŒ Error getting system info: " << e.what() << "\n";
    }
    
    return info.str();
}

// ArUco æ£€æµ‹å‚æ•°è®¾ç½®æ–¹æ³•å®ç°
void VideoStreamer::setArUcoDetectionParameters(int adaptiveThreshWinSizeMin, int adaptiveThreshWinSizeMax, 
                                               int adaptiveThreshWinSizeStep, double adaptiveThreshConstant) {
    homographyMapper_.setDetectionParameters(adaptiveThreshWinSizeMin, adaptiveThreshWinSizeMax, 
                                           adaptiveThreshWinSizeStep, adaptiveThreshConstant);
}

void VideoStreamer::setArUcoCornerRefinementMethod(int method) {
    homographyMapper_.setCornerRefinementMethod(method);
}

void VideoStreamer::getArUcoDetectionParameters(int& adaptiveThreshWinSizeMin, int& adaptiveThreshWinSizeMax, 
                                               int& adaptiveThreshWinSizeStep, double& adaptiveThreshConstant) const {
    homographyMapper_.getDetectionParameters(adaptiveThreshWinSizeMin, adaptiveThreshWinSizeMax, 
                                           adaptiveThreshWinSizeStep, adaptiveThreshConstant);
}

int VideoStreamer::getArUcoCornerRefinementMethod() const {
    return homographyMapper_.getCornerRefinementMethod();
}

// åæ ‡å˜æ¢æ ‡å®šæ¨¡å¼æ§åˆ¶æ–¹æ³•å®ç°
bool VideoStreamer::toggleCalibrationMode() {
    calibrationMode_ = !calibrationMode_;
    
    std::cout << "ğŸ“ [COORDINATE CALIBRATION] æ ‡å®šæ¨¡å¼åˆ‡æ¢: " << (calibrationMode_ ? "å¯ç”¨" : "ç¦ç”¨") << std::endl;
    
    return calibrationMode_;
}

bool VideoStreamer::isCalibrationMode() const {
    return calibrationMode_;
}

// é”™è¯¯é€šçŸ¥æ–¹æ³•å®ç°
void VideoStreamer::sendErrorNotification(const std::string& errorType, const std::string& title, const std::string& message) {
    // æ„å»ºé”™è¯¯é€šçŸ¥JSON
    std::string errorNotification = "{"
        "\"type\":\"error_notification\","
        "\"error_type\":\"" + errorType + "\","
        "\"title\":\"" + title + "\","
        "\"message\":\"" + message + "\","
        "\"timestamp\":\"" + std::to_string(std::time(nullptr)) + "\""
    "}";
    
    std::cout << "ğŸš¨ [ERROR NOTIFICATION] " << errorType << ": " << title << " - " << message << std::endl;
    
    // å¹¿æ’­é”™è¯¯é€šçŸ¥åˆ°æ‰€æœ‰WebSocketè¿æ¥
    std::lock_guard<std::mutex> lock(conn_mutex_);
    for (auto& conn : connections_) {
        try {
            conn->send_text(errorNotification);
        } catch (const std::exception& e) {
            std::cerr << "Error sending error notification: " << e.what() << std::endl;
        }
    }
}

// æ‘„åƒå¤´æ¢å¤å°è¯•æ–¹æ³•å®ç°
void VideoStreamer::attemptCameraRecovery() {
    std::cout << "ğŸ”§ [CAMERA RECOVERY] å°è¯•æ¢å¤æ‘„åƒå¤´è®¾å¤‡..." << std::endl;
    
    // é‡Šæ”¾å½“å‰æ‘„åƒå¤´èµ„æº
    if (cap_.isOpened()) {
        cap_.release();
        std::this_thread::sleep_for(std::chrono::milliseconds(500)); // ç­‰å¾…èµ„æºé‡Šæ”¾
    }
    
    // å°è¯•é‡æ–°åˆå§‹åŒ–æ‘„åƒå¤´
    bool recoverySuccess = false;
    
    // å°è¯•é‡æ–°æ‰“å¼€è®¾å¤‡
    if (autoDetectCamera()) {
        // å°è¯•è®¾ç½®ä¹‹å‰çš„åˆ†è¾¨ç‡
        cap_.set(cv::CAP_PROP_FRAME_WIDTH, width_);
        cap_.set(cv::CAP_PROP_FRAME_HEIGHT, height_);
        cap_.set(cv::CAP_PROP_FPS, fps_);
        
        // éªŒè¯è®¾å¤‡æ˜¯å¦æ­£å¸¸å·¥ä½œ
        cv::Mat testFrame;
        if (cap_.read(testFrame) && !testFrame.empty()) {
            recoverySuccess = true;
            frameReadFailureCount_ = 0;  // é‡ç½®å¤±è´¥è®¡æ•°å™¨
            std::cout << "âœ… [CAMERA RECOVERY] æ‘„åƒå¤´æ¢å¤æˆåŠŸ" << std::endl;
            sendErrorNotification("camera_recovery_success", "æ‘„åƒå¤´æ¢å¤æˆåŠŸ", "è®¾å¤‡é‡æ–°åˆå§‹åŒ–å®Œæˆ");
        }
    }
    
    if (!recoverySuccess) {
        std::cout << "âŒ [CAMERA RECOVERY] æ‘„åƒå¤´æ¢å¤å¤±è´¥" << std::endl;
        sendErrorNotification("camera_recovery_failed", "æ‘„åƒå¤´æ¢å¤å¤±è´¥", 
                            "æ— æ³•é‡æ–°åˆå§‹åŒ–æ‘„åƒå¤´ï¼Œè¯·æ£€æŸ¥è®¾å¤‡è¿æ¥æˆ–é‡å¯ç¨‹åº");
    }
}
