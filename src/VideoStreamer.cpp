#include "VideoStreamer.h"
#include <iostream>
#include <vector>
#include <chrono>
#include <opencv2/imgcodecs.hpp>

using namespace std;
using namespace std::chrono_literals;

VideoStreamer::VideoStreamer() : width_(1920), height_(1080), fps_(30) {
    // åˆå§‹åŒ–
    // å°è¯•åŠ è½½å·²æœ‰çš„æ ‡å®šæ•°æ®
    std::ifstream file(calibrationFilePath_);
    if (file.good()) {
        file.close();
        loadHomography(calibrationFilePath_);
    }
    
    // å¯ç”¨ä¿å­˜æ ‡å®šå›¾åƒåŠŸèƒ½
    cameraCalibrator_.setSaveCalibrationImages(true);
    std::cout << "Camera calibrator initialized, saveCalibrationImages set to true" << std::endl;
    
    // åˆå§‹åŒ–åŒåˆ†è¾¨ç‡è®¾ç½®
    displayWidth_ = 960;     // æ˜¾ç¤ºåˆ†è¾¨ç‡ï¼š16:9æ¯”ä¾‹
    displayHeight_ = 540;
    detectionWidth_ = 1920;  // æ£€æµ‹åˆ†è¾¨ç‡ï¼šé«˜ç²¾åº¦
    detectionHeight_ = 1080;
}

VideoStreamer::~VideoStreamer() {
    stop();
}

bool VideoStreamer::initialize(int camera_id, int width, int height, int fps) {
    // å…³é—­å½“å‰æ‘„åƒå¤´
    if (cap_.isOpened()) {
        cap_.release();
    }
    
    // å¦‚æœæŒ‡å®šäº†æ‘„åƒå¤´IDï¼Œåˆ™ä½¿ç”¨æŒ‡å®šçš„æ‘„åƒå¤´
    if (camera_id >= 0) {
        if (!cap_.open(camera_id, cv::CAP_V4L2)) {
            cerr << "Error: Could not open camera " << camera_id << " with V4L2 backend" << endl;
            return false;
        }
    } else {
        // å¦åˆ™å°è¯•è‡ªåŠ¨æ£€æµ‹æ‘„åƒå¤´
        if (!autoDetectCamera()) {
            std::cerr << "Error: Could not auto-detect any camera device" << std::endl;
            std::cout << "Using simulation mode instead" << std::endl;
            
            // åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿå›¾åƒ
            frame_ = cv::Mat(height, width, CV_8UC3, cv::Scalar(200, 200, 200));
            
            // åœ¨å›¾åƒä¸Šç»˜åˆ¶æ–‡å­—
            cv::putText(frame_, "Simulation Mode - No Camera", cv::Point(50, height/2 - 30), 
                        cv::FONT_HERSHEY_SIMPLEX, 0.8, cv::Scalar(0, 0, 0), 2);
            cv::putText(frame_, "Testing Matrix Display & Export", cv::Point(50, height/2 + 30), 
                        cv::FONT_HERSHEY_SIMPLEX, 0.8, cv::Scalar(0, 0, 0), 2);
            
            // åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„å•åº”æ€§çŸ©é˜µ
            cv::Mat simulatedMatrix = (cv::Mat_<double>(3, 3) << 
                1.2, 0.1, -50.5,
                0.05, 1.3, -30.2,
                0.001, 0.002, 1.0);
            
            // è®¾ç½®åˆ° HomographyMapper ä¸­
            homographyMapper_.setHomographyMatrix(simulatedMatrix);
            
            // æ ‡è®°ä¸ºå·²æ ‡å®šçŠ¶æ€
            homographyMapper_.setCalibrated(true);
            
            // è¿”å›æˆåŠŸ
            return true;
        }
    }
    
    // æ£€æŸ¥æ‘„åƒå¤´æ˜¯å¦æˆåŠŸæ‰“å¼€
    if (!cap_.isOpened()) {
        std::cerr << "Failed to initialize camera" << std::endl;
        return false;
    }
    
    width_ = width;
    height_ = height;
    fps_ = fps;

    // è®¾ç½®æ‘„åƒå¤´å‚æ•°
    cap_.set(cv::CAP_PROP_FRAME_WIDTH, width_);
    cap_.set(cv::CAP_PROP_FRAME_HEIGHT, height_);
    cap_.set(cv::CAP_PROP_FPS, fps_);
    cap_.set(cv::CAP_PROP_FOURCC, cv::VideoWriter::fourcc('M', 'J', 'P', 'G'));

    // éªŒè¯å‚æ•°
    double actual_width = cap_.get(cv::CAP_PROP_FRAME_WIDTH);
    double actual_height = cap_.get(cv::CAP_PROP_FRAME_HEIGHT);
    double actual_fps = cap_.get(cv::CAP_PROP_FPS);

    cout << "Camera initialized with parameters:" << endl;
    cout << "  Resolution: " << actual_width << "x" << actual_height << endl;
    cout << "  FPS: " << actual_fps << endl;

    return true;
}

bool VideoStreamer::autoDetectCamera() {
    // å°è¯•ç›´æ¥ä½¿ç”¨è®¾å¤‡è·¯å¾„æ‰“å¼€æ‘„åƒå¤´
    std::vector<std::string> device_paths = {
        "/dev/video0",
        "/dev/video2"
    };
    
    for (const auto& device_path : device_paths) {
        std::cout << "Trying to open camera device: " << device_path << std::endl;
        
        // ç›´æ¥å°†æ‘„åƒå¤´æ‰“å¼€åˆ°æˆ‘ä»¬çš„ä¸»æ•è·å™¨ä¸­
        // è®¾ç½®æ‘„åƒå¤´å‚æ•°ä»¥ä½¿ç”¨MJPEGæ ¼å¼
        cap_.set(cv::CAP_PROP_FOURCC, cv::VideoWriter::fourcc('M', 'J', 'P', 'G'));
        
        // ç›´æ¥ä½¿ç”¨è®¾å¤‡è·¯å¾„æ‰“å¼€æ‘„åƒå¤´
        if (cap_.open(device_path, cv::CAP_V4L2)) {
            // å°è¯•æ•è·ä¸€å¸§æ¥éªŒè¯è®¾å¤‡
            cv::Mat test_frame;
            cap_ >> test_frame;
            
            if (!test_frame.empty()) {
                std::cout << "Successfully opened camera device: " << device_path << " (MJPEG mode)" << std::endl;
                
                // æ‰“å°æ‘„åƒå¤´ä¿¡æ¯
                double width = cap_.get(cv::CAP_PROP_FRAME_WIDTH);
                double height = cap_.get(cv::CAP_PROP_FRAME_HEIGHT);
                double fps = cap_.get(cv::CAP_PROP_FPS);
                std::cout << "Camera info - Width: " << width << ", Height: " << height << ", FPS: " << fps << std::endl;
                
                // æ‘„åƒå¤´æˆåŠŸæ‰“å¼€å¹¶æ•è·äº†ä¸€å¸§ï¼Œè¿”å›æˆåŠŸ
                return true;
            } else {
                std::cerr << "Failed to capture frame from camera device: " << device_path << std::endl;
                // å…³é—­æ‘„åƒå¤´å¹¶å°è¯•ä¸‹ä¸€ä¸ªè®¾å¤‡
                cap_.release();
            }
        } else {
            std::cerr << "Failed to open camera device: " << device_path << std::endl;
        }
    }
    
    // å¦‚æœæ‰€æœ‰è®¾å¤‡è·¯å¾„éƒ½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ç´¢å¼•
    std::vector<int> indices = {0, 1, 2, 3, 4};
    for (int idx : indices) {
        std::cout << "Trying to open camera with index: " << idx << std::endl;
        
        // è®¾ç½®æ‘„åƒå¤´å‚æ•°ä»¥ä½¿ç”¨MJPEGæ ¼å¼
        cap_.set(cv::CAP_PROP_FOURCC, cv::VideoWriter::fourcc('M', 'J', 'P', 'G'));
        
        if (cap_.open(idx, cv::CAP_V4L2)) {
            cv::Mat test_frame;
            cap_ >> test_frame;
            
            if (!test_frame.empty()) {
                std::cout << "Successfully opened camera with index: " << idx << std::endl;
                return true;
            } else {
                std::cerr << "Failed to capture frame from camera with index: " << idx << std::endl;
                cap_.release();
            }
        } else {
            std::cerr << "Failed to open camera with index: " << idx << std::endl;
        }
    }
    
    return false; // æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ‘„åƒå¤´è®¾å¤‡
}

std::vector<std::pair<int, int>> VideoStreamer::getSupportedResolutions() {
    // å¸¸è§çš„æ‘„åƒå¤´æ”¯æŒçš„åˆ†è¾¨ç‡
    std::vector<std::pair<int, int>> resolutions = {
        {640, 480},    // VGA
        {800, 600},    // SVGA
        {1024, 768},   // XGA
        {1280, 720},   // HD
        {1280, 960},   // SXGA-
        {1920, 1080}   // Full HD
    };
    
    // å¦‚æœæ‘„åƒå¤´æœªæ‰“å¼€ï¼Œè¿”å›é»˜è®¤åˆ—è¡¨
    if (!cap_.isOpened()) {
        return resolutions;
    }
    
    // éªŒè¯æ‘„åƒå¤´æ”¯æŒçš„åˆ†è¾¨ç‡
    std::vector<std::pair<int, int>> supported_resolutions;
    
    // ä¿å­˜å½“å‰åˆ†è¾¨ç‡
    double current_width = cap_.get(cv::CAP_PROP_FRAME_WIDTH);
    double current_height = cap_.get(cv::CAP_PROP_FRAME_HEIGHT);
    
    // æ£€æŸ¥æ¯ä¸ªåˆ†è¾¨ç‡æ˜¯å¦æ”¯æŒ
    for (const auto& res : resolutions) {
        // å°è¯•è®¾ç½®åˆ†è¾¨ç‡
        cap_.set(cv::CAP_PROP_FRAME_WIDTH, res.first);
        cap_.set(cv::CAP_PROP_FRAME_HEIGHT, res.second);
        
        // è·å–å®é™…è®¾ç½®çš„åˆ†è¾¨ç‡
        double actual_width = cap_.get(cv::CAP_PROP_FRAME_WIDTH);
        double actual_height = cap_.get(cv::CAP_PROP_FRAME_HEIGHT);
        
        // å¦‚æœå®é™…åˆ†è¾¨ç‡ä¸è¯·æ±‚çš„åˆ†è¾¨ç‡æ¥è¿‘ï¼Œåˆ™è®¤ä¸ºæ”¯æŒ
        if (std::abs(actual_width - res.first) < 10 && std::abs(actual_height - res.second) < 10) {
            supported_resolutions.push_back({static_cast<int>(actual_width), static_cast<int>(actual_height)});
            cout << "Supported resolution: " << actual_width << "x" << actual_height << endl;
        }
    }
    
    // æ¢å¤åŸå§‹åˆ†è¾¨ç‡
    cap_.set(cv::CAP_PROP_FRAME_WIDTH, current_width);
    cap_.set(cv::CAP_PROP_FRAME_HEIGHT, current_height);
    
    return supported_resolutions.empty() ? resolutions : supported_resolutions;
}

bool VideoStreamer::setResolution(int width, int height) {
    if (!cap_.isOpened()) {
        cerr << "Error: Camera not initialized" << endl;
        return false;
    }
    
    // è®¾ç½®æ–°åˆ†è¾¨ç‡
    cap_.set(cv::CAP_PROP_FRAME_WIDTH, width);
    cap_.set(cv::CAP_PROP_FRAME_HEIGHT, height);
    
    // éªŒè¯åˆ†è¾¨ç‡æ˜¯å¦è®¾ç½®æˆåŠŸ
    double actual_width = cap_.get(cv::CAP_PROP_FRAME_WIDTH);
    double actual_height = cap_.get(cv::CAP_PROP_FRAME_HEIGHT);
    
    // æ›´æ–°å†…éƒ¨åˆ†è¾¨ç‡å˜é‡
    width_ = static_cast<int>(actual_width);
    height_ = static_cast<int>(actual_height);
    
    cout << "Resolution set to: " << width_ << "x" << height_ << endl;
    
    // å¦‚æœå®é™…åˆ†è¾¨ç‡ä¸è¯·æ±‚çš„åˆ†è¾¨ç‡æ¥è¿‘ï¼Œåˆ™è®¤ä¸ºè®¾ç½®æˆåŠŸ
    return (std::abs(actual_width - width) < 10 && std::abs(actual_height - height) < 10);
}

std::pair<int, int> VideoStreamer::getCurrentResolution() {
    if (!cap_.isOpened()) {
        return {width_, height_}; // è¿”å›å†…éƒ¨å­˜å‚¨çš„åˆ†è¾¨ç‡
    }
    
    // è·å–å½“å‰åˆ†è¾¨ç‡
    double width = cap_.get(cv::CAP_PROP_FRAME_WIDTH);
    double height = cap_.get(cv::CAP_PROP_FRAME_HEIGHT);
    
    return {static_cast<int>(width), static_cast<int>(height)};
}

void VideoStreamer::start() {
    if (!cap_.isOpened()) {
        cerr << "Error: Camera not initialized" << endl;
        return;
    }
    
    running_ = true;
    worker_ = thread(&VideoStreamer::captureThread, this);
    
    // å¯åŠ¨å¹¿æ’­çº¿ç¨‹
    thread broadcast_thread([this]() {
        while (running_) {
            this_thread::sleep_for(chrono::milliseconds(1000 / fps_));
            broadcastFrame();
        }
    });
    broadcast_thread.detach();
    
    cout << "Video stream started" << endl;
}

void VideoStreamer::stop() {
    if (running_) {
        running_ = false;
        if (worker_.joinable()) {
            worker_.join();
        }
    }
    
    {
        std::lock_guard<std::mutex> lock(conn_mutex_);
        connections_.clear();
    }
    
    if (cap_.isOpened()) {
        cap_.release();
    }
    
    cout << "Video streaming stopped" << endl;
}

void VideoStreamer::handleWebSocket(const crow::request& req, Connection conn) {
    // æ·»åŠ è¿æ¥åˆ°é›†åˆ
    {
        std::lock_guard<std::mutex> lock(conn_mutex_);
        connections_.insert(conn);
        std::cout << "WebSocket connection added to VideoStreamer, total connections: " << connections_.size() << std::endl;
    }
    
    // å‘é€æ‘„åƒå¤´ä¿¡æ¯ç»™å®¢æˆ·ç«¯
    sendCameraInfo(conn);
}

void VideoStreamer::removeWebSocketConnection(Connection conn) {
    std::lock_guard<std::mutex> lock(conn_mutex_);
    auto it = connections_.find(conn);
    if (it != connections_.end()) {
        connections_.erase(it);
        std::cout << "WebSocket connection removed from VideoStreamer, remaining connections: " << connections_.size() << std::endl;
    }
}

void VideoStreamer::sendCameraInfo(Connection conn) {
    if (!conn) return;
    
    try {
        // è·å–æ‘„åƒå¤´æ”¯æŒçš„åˆ†è¾¨ç‡
        auto resolutions = getSupportedResolutions();
        auto current_res = getCurrentResolution();
        
        // æ„å»ºåˆ†è¾¨ç‡JSONæ•°ç»„
        std::string res_array = "[";
        for (size_t i = 0; i < resolutions.size(); ++i) {
            res_array += "{\"width\":"
                      + std::to_string(resolutions[i].first) + ",\"height\":"
                      + std::to_string(resolutions[i].second) + "}";
            if (i < resolutions.size() - 1) {
                res_array += ",";
            }
        }
        res_array += "]";
        
        // è·å–æ£‹ç›˜æ ¼å‚æ•°
        cv::Size boardSize = cameraCalibrator_.getBoardSize();
        float squareSize = cameraCalibrator_.getSquareSize();
        
        // æ„å»ºæ‘„åƒå¤´ä¿¡æ¯æ¶ˆæ¯
        std::string info_message = std::string("{\"type\":\"camera_info\",")
                              + "\"current_width\":"
                              + std::to_string(current_res.first) + ","
                              + "\"current_height\":"
                              + std::to_string(current_res.second) + ","
                              + "\"fps\":"
                              + std::to_string(fps_) + ","
                              + "\"calibration_mode\":"
                              + (calibrationMode_ ? "true" : "false") + ","
                              + "\"calibrated\":"
                              + (homographyMapper_.isCalibrated() ? "true" : "false") + ","
                              + "\"board_width\":"
                              + std::to_string(boardSize.width) + ","
                              + "\"board_height\":"
                              + std::to_string(boardSize.height) + ","
                              + "\"square_size\":"
                              + std::to_string(int(squareSize * 1000)) + ","
                              + "\"resolutions\":"
                              + res_array + "}";
        
        // å‘é€æ¶ˆæ¯
        conn->send_text(info_message);
        
    } catch (const std::exception& e) {
        std::cerr << "Error sending camera info: " << e.what() << std::endl;
    }
}

// å•åº”æ€§çŸ©é˜µæ ‡å®šç›¸å…³æ–¹æ³•çš„å®ç°
bool VideoStreamer::addCalibrationPoint(const cv::Point2f& imagePoint, const cv::Point2f& groundPoint) {
    homographyMapper_.addCalibrationPoint(imagePoint, groundPoint);
    return true;
}

bool VideoStreamer::removeLastCalibrationPoint() {
    auto points = homographyMapper_.getCalibrationPoints();
    if (points.empty()) {
        return false;
    }
    
    homographyMapper_.clearCalibrationPoints();
    
    // é‡æ–°æ·»åŠ é™¤äº†æœ€åä¸€ä¸ªä¹‹å¤–çš„æ‰€æœ‰ç‚¹
    for (size_t i = 0; i < points.size() - 1; ++i) {
        homographyMapper_.addCalibrationPoint(points[i].first, points[i].second);
    }
    
    return true;
}

bool VideoStreamer::clearCalibrationPoints() {
    homographyMapper_.clearCalibrationPoints();
    return true;
}

bool VideoStreamer::computeHomography() {
    return homographyMapper_.computeHomography();
}

bool VideoStreamer::saveHomography(const std::string& filename) {
    return homographyMapper_.saveHomography(filename.empty() ? calibrationFilePath_ : filename);
}

bool VideoStreamer::loadHomography(const std::string& filename) {
    return homographyMapper_.loadHomography(filename.empty() ? calibrationFilePath_ : filename);
}

cv::Point2f VideoStreamer::imageToGround(const cv::Point2f& imagePoint) {
    return homographyMapper_.imageToGround(imagePoint);
}

cv::Point2f VideoStreamer::groundToImage(const cv::Point2f& groundPoint) {
    return homographyMapper_.groundToImage(groundPoint);
}

bool VideoStreamer::isCalibrated() const {
    return homographyMapper_.isCalibrated();
}

std::vector<std::pair<cv::Point2f, cv::Point2f>> VideoStreamer::getCalibrationPoints() const {
    return homographyMapper_.getCalibrationPoints();
}

cv::Mat VideoStreamer::getHomographyMatrix() const {
    return homographyMapper_.getHomographyMatrix();
}

// ArUco æ ‡è®°ç›¸å…³æ–¹æ³•å®ç°
bool VideoStreamer::toggleArUcoMode() {
    arucoMode_ = !arucoMode_;
    return arucoMode_;
}

bool VideoStreamer::isArUcoMode() const {
    return arucoMode_;
}

bool VideoStreamer::detectArUcoMarkers(cv::Mat& frame) {
    if (!arucoMode_) return false;
    
    // æ£€æµ‹æ ‡è®°
    std::vector<int> markerIds;
    std::vector<std::vector<cv::Point2f>> markerCorners;
    
    bool detected = homographyMapper_.detectArUcoMarkers(frame, markerIds, markerCorners);
    
    if (detected) {
        // ç»˜åˆ¶æ£€æµ‹åˆ°çš„æ ‡è®°
        homographyMapper_.drawDetectedMarkers(frame, markerIds, markerCorners);
        
        // åœ¨ç”»é¢ä¸Šæ˜¾ç¤ºæ£€æµ‹åˆ°çš„æ ‡è®°æ•°é‡
        cv::putText(frame, "æ£€æµ‹åˆ° " + std::to_string(markerIds.size()) + " ä¸ªArUcoæ ‡è®°", 
                   cv::Point(10, 30), cv::FONT_HERSHEY_SIMPLEX, 0.7, cv::Scalar(0, 255, 0), 2);
    } else {
        // æ˜¾ç¤ºæœªæ£€æµ‹åˆ°æ ‡è®°çš„ä¿¡æ¯
        cv::putText(frame, "æœªæ£€æµ‹åˆ°ArUcoæ ‡è®°", 
                   cv::Point(10, 30), cv::FONT_HERSHEY_SIMPLEX, 0.7, cv::Scalar(0, 0, 255), 2);
    }
    
    return detected;
}

bool VideoStreamer::calibrateFromArUcoMarkers() {
    if (!arucoMode_) return false;
    
    std::lock_guard<std::mutex> lock(mutex_);
    if (frame_.empty()) return false;
    
    // ä½¿ç”¨å½“å‰å¸§å’Œæ ‡è®°åœ°é¢åæ ‡è¿›è¡Œæ ‡å®š
    return homographyMapper_.calibrateFromArUcoMarkers(frame_, homographyMapper_.getMarkerGroundCoordinates());
}

bool VideoStreamer::setMarkerGroundCoordinates(int markerId, const cv::Point2f& groundCoord) {
    homographyMapper_.setMarkerGroundCoordinates(markerId, groundCoord);
    return true;
}

bool VideoStreamer::saveMarkerCoordinates(const std::string& filename) {
    std::string targetFile = filename.empty() ? markerCoordinatesFilePath_ : filename;
    return homographyMapper_.saveMarkerGroundCoordinates(targetFile);
}

bool VideoStreamer::loadMarkerCoordinates(const std::string& filename) {
    std::string targetFile = filename.empty() ? markerCoordinatesFilePath_ : filename;
    return homographyMapper_.loadMarkerGroundCoordinates(targetFile);
}

void VideoStreamer::drawCalibrationPoints(cv::Mat& frame) {
    auto points = homographyMapper_.getCalibrationPoints();
    
    // ç»˜åˆ¶æ ‡å®šç‚¹
    for (size_t i = 0; i < points.size(); ++i) {
        // ç»˜åˆ¶å¤–åœˆ
        cv::circle(frame, points[i].first, 12, cv::Scalar(0, 255, 255), 2);
        // ç»˜åˆ¶å†…åœˆ
        cv::circle(frame, points[i].first, 5, cv::Scalar(0, 0, 255), -1);
        // ç»˜åˆ¶åå­—çº¿
        cv::line(frame, cv::Point(points[i].first.x - 15, points[i].first.y),
                 cv::Point(points[i].first.x + 15, points[i].first.y),
                 cv::Scalar(0, 255, 0), 1);
        cv::line(frame, cv::Point(points[i].first.x, points[i].first.y - 15),
                 cv::Point(points[i].first.x, points[i].first.y + 15),
                 cv::Scalar(0, 255, 0), 1);
        
        // ç»˜åˆ¶ç‚¹ç¼–å·
        cv::putText(frame, std::to_string(i + 1), 
                   cv::Point(points[i].first.x + 15, points[i].first.y - 10), 
                   cv::FONT_HERSHEY_SIMPLEX, 0.7, cv::Scalar(0, 0, 255), 2);
        
        // ç»˜åˆ¶åœ°é¢åæ ‡
        std::string coordText = "(" + std::to_string(int(points[i].second.x)) + "," + 
                               std::to_string(int(points[i].second.y)) + ")";
        cv::putText(frame, coordText, 
                   cv::Point(points[i].first.x + 15, points[i].first.y + 15), 
                   cv::FONT_HERSHEY_SIMPLEX, 0.6, cv::Scalar(255, 0, 0), 2);
    }
    
    // å¦‚æœå·²ç»æ ‡å®šï¼Œç»˜åˆ¶ç½‘æ ¼çº¿æ¥æ˜¾ç¤ºæ ‡å®šæ•ˆæœ
    if (homographyMapper_.isCalibrated() && points.size() >= 4) {
        // ç»˜åˆ¶ç½‘æ ¼çº¿æ¥æ˜¾ç¤ºæ ‡å®šæ•ˆæœ
        int gridSize = 50; // ç½‘æ ¼å¤§å°ï¼ˆåœ°é¢åæ ‡ç³»ä¸­ï¼‰
        int gridCount = 10; // ç½‘æ ¼æ•°é‡
        
        // æ‰¾åˆ°æ ‡å®šç‚¹çš„è¾¹ç•Œæ¡†
        float minX = std::numeric_limits<float>::max();
        float minY = std::numeric_limits<float>::max();
        float maxX = std::numeric_limits<float>::min();
        float maxY = std::numeric_limits<float>::min();
        
        for (const auto& point : points) {
            minX = std::min(minX, point.second.x);
            minY = std::min(minY, point.second.y);
            maxX = std::max(maxX, point.second.x);
            maxY = std::max(maxY, point.second.y);
        }
        
        // ç»˜åˆ¶æ°´å¹³çº¿
        for (int i = 0; i <= gridCount; ++i) {
            float y = minY + i * gridSize;
            if (y > maxY) break;
            
            cv::Point2f start = groundToImage(cv::Point2f(minX, y));
            cv::Point2f end = groundToImage(cv::Point2f(maxX, y));
            
            cv::line(frame, start, end, cv::Scalar(0, 255, 0), 1);
            
            // æ ‡è®°åæ ‡
            cv::putText(frame, std::to_string(int(y)), 
                       cv::Point(start.x + 5, start.y), 
                       cv::FONT_HERSHEY_SIMPLEX, 0.3, cv::Scalar(0, 255, 0), 1);
        }
        
        // ç»˜åˆ¶å‚ç›´çº¿
        for (int i = 0; i <= gridCount; ++i) {
            float x = minX + i * gridSize;
            if (x > maxX) break;
            
            cv::Point2f start = groundToImage(cv::Point2f(x, minY));
            cv::Point2f end = groundToImage(cv::Point2f(x, maxY));
            
            cv::line(frame, start, end, cv::Scalar(0, 255, 0), 1);
            
            // æ ‡è®°åæ ‡
            cv::putText(frame, std::to_string(int(x)), 
                       cv::Point(start.x, start.y + 15), 
                       cv::FONT_HERSHEY_SIMPLEX, 0.3, cv::Scalar(0, 255, 0), 1);
        }
    }
    
    // æ·»åŠ æ ‡å®šçŠ¶æ€ä¿¡æ¯
    std::string statusText = "Calibration Mode: " + std::string(calibrationMode_ ? "ON" : "OFF");
    cv::putText(frame, statusText, cv::Point(10, 30), cv::FONT_HERSHEY_SIMPLEX, 0.7, cv::Scalar(0, 0, 255), 2);
    
    if (homographyMapper_.isCalibrated()) {
        cv::putText(frame, "Calibrated: YES", cv::Point(10, 60), cv::FONT_HERSHEY_SIMPLEX, 0.7, cv::Scalar(0, 255, 0), 2);
    } else {
        cv::putText(frame, "Calibrated: NO (Need 4+ points)", cv::Point(10, 60), cv::FONT_HERSHEY_SIMPLEX, 0.7, cv::Scalar(0, 0, 255), 2);
    }
    
    cv::putText(frame, "Points: " + std::to_string(points.size()), cv::Point(10, 90), cv::FONT_HERSHEY_SIMPLEX, 0.7, cv::Scalar(255, 0, 0), 2);
}

void VideoStreamer::broadcastFrame() {
    static int frame_count = 0;  // é™æ€å¸§è®¡æ•°å™¨
    
    // æ£€æŸ¥æ˜¯å¦æœ‰è¿æ¥
    if (connections_.empty()) {
        return;
    }
    
    cv::Mat processedFrame;
    
    // æ ¹æ®æ¨¡å¼é€‰æ‹©åˆé€‚çš„å¸§åˆ†è¾¨ç‡
    if (cameraCalibrationMode_) {
        // ç›¸æœºæ ‡å®šæ¨¡å¼ï¼šä½¿ç”¨ä¼˜åŒ–çš„æ˜¾ç¤ºå¸§ï¼ˆå·²åŒ…å«è§’ç‚¹ç»˜åˆ¶ï¼‰
        processedFrame = getDisplayFrame();
        if (processedFrame.empty()) {
            return;
        }
    } else {
        // æ™®é€šæ¨¡å¼ï¼šä½¿ç”¨åŸå§‹å¸§
        std::lock_guard<std::mutex> lock(mutex_);
        if (frame_.empty()) {
            return;
        }
        processedFrame = frame_.clone();
    }
    
    // éªŒè¯å¸§æ•°æ®å®Œæ•´æ€§
    if (processedFrame.empty() || processedFrame.cols <= 0 || processedFrame.rows <= 0) {
        std::cerr << "Warning: Invalid frame data, skipping broadcast" << std::endl;
        return;
    }
    
    // å¦‚æœåœ¨æ ‡å®šæ¨¡å¼ä¸‹ï¼Œç»˜åˆ¶æ ‡å®šç‚¹
    if (calibrationMode_) {
        drawCalibrationPoints(processedFrame);
    }
    
    // å¦‚æœåœ¨ArUcoæ¨¡å¼ä¸‹ï¼Œæ£€æµ‹å¹¶ç»˜åˆ¶ArUcoæ ‡è®°
    if (arucoMode_) {
        detectArUcoMarkers(processedFrame);
    }
    
    // åœ¨ç¼–ç å‰è¿›ä¸€æ­¥éªŒè¯å¸§çš„æœ‰æ•ˆæ€§
    if (processedFrame.type() != CV_8UC3 && processedFrame.type() != CV_8UC1) {
        std::cerr << "Warning: Invalid frame type for JPEG encoding: " << processedFrame.type() << std::endl;
        return;
    }
    
    // éªŒè¯å¸§æ˜¯å¦è¿ç»­
    if (!processedFrame.isContinuous()) {
        // å¦‚æœä¸è¿ç»­ï¼Œåˆ›å»ºä¸€ä¸ªè¿ç»­çš„å‰¯æœ¬
        processedFrame = processedFrame.clone();
    }
    
    // å°†å¸§ç¼–ç ä¸ºJPEGï¼Œä½¿ç”¨æ›´é«˜è´¨é‡å‚æ•°å’Œé”™è¯¯æ£€æŸ¥
    std::vector<uchar> buf;
    std::vector<int> encode_params = {
        cv::IMWRITE_JPEG_QUALITY, 85,  // æé«˜JPEGè´¨é‡åˆ°85%
        cv::IMWRITE_JPEG_OPTIMIZE, 1   // å¯ç”¨JPEGä¼˜åŒ–
    };
    
    bool encode_success = false;
    try {
        encode_success = cv::imencode(".jpg", processedFrame, buf, encode_params);
    } catch (const cv::Exception& e) {
        std::cerr << "OpenCV error in JPEG encoding: " << e.what() << std::endl;
        return;
    } catch (const std::exception& e) {
        std::cerr << "Error in JPEG encoding: " << e.what() << std::endl;
        return;
    }
    
    // æ£€æŸ¥ç¼–ç æ˜¯å¦æˆåŠŸ
    if (!encode_success || buf.empty()) {
        std::cerr << "Warning: JPEG encoding failed, skipping frame transmission" << std::endl;
        return;
    }
    
    // éªŒè¯ç¼–ç ç»“æœçš„å¤§å°åˆç†æ€§
    if (buf.size() < 100 || buf.size() > 1024 * 1024) {  // 100å­—èŠ‚åˆ°1MBä¹‹é—´
        std::cerr << "Warning: JPEG encoded size abnormal (" << buf.size() 
                  << " bytes), skipping frame transmission" << std::endl;
        return;
    }
    
    // æ¯100å¸§å‘é€ä¸€æ¬¡åˆ†è¾¨ç‡ä¿¡æ¯
    if (frame_count % 100 == 0) {
        // æ„å»ºå¸§ä¿¡æ¯æ¶ˆæ¯
        std::string info_message = std::string("{\"type\":\"frame_info\",\"width\":")
                              + std::to_string(processedFrame.cols) + ",\"height\":"
                              + std::to_string(processedFrame.rows) + "}";
        
        // å¹¿æ’­å¸§ä¿¡æ¯
        std::lock_guard<std::mutex> conn_lock(conn_mutex_);
        for (auto conn : connections_) {
            if (conn) {
                try {
                    conn->send_text(info_message);
                } catch (const std::exception& e) {
                    std::cerr << "Error sending frame info: " << e.what() << std::endl;
                }
            }
        }
    }
    
    // å¹¿æ’­å¸§æ•°æ® - æ·»åŠ å¼‚å¸¸å¤„ç†
    {
        std::lock_guard<std::mutex> lock(conn_mutex_);
        for (auto conn : connections_) {
            if (conn) {
                try {
                    conn->send_binary(std::string(buf.begin(), buf.end()));
                } catch (const std::exception& e) {
                    std::cerr << "Error sending frame data: " << e.what() << std::endl;
                }
            }
        }
    }
    
    frame_count++;
}

bool VideoStreamer::getFrame(cv::Mat& frame) {
    std::lock_guard<std::mutex> lock(mutex_);
    if (frame_.empty()) {
        return false;
    }
    
    frame = frame_.clone();
    return true;
}

void VideoStreamer::captureThread() {
    cv::Mat frame;
    
    while (running_) {
        if (cap_.read(frame)) {
            if (frame.empty()) {
                cerr << "Error: Empty frame received" << endl;
                continue;
            }
            
            // éªŒè¯å¸§æ•°æ®å®Œæ•´æ€§
            if (frame.cols <= 0 || frame.rows <= 0) {
                cerr << "Error: Invalid frame dimensions" << endl;
                continue;
            }
            
            // åˆ›å»ºå¤„ç†å¸§çš„å‰¯æœ¬ï¼Œé¿å…ä¿®æ”¹åŸå§‹å¸§
            cv::Mat processedFrame = frame.clone();
            
            // å¦‚æœå·²ç»å®Œæˆç›¸æœºæ ‡å®šä¸”å¯ç”¨äº†æ ¡æ­£ï¼Œåˆ™è¿›è¡Œå›¾åƒæ ¡æ­£
            if (isCameraCalibrated() && cameraCorrectionEnabled_) {
                try {
                    cv::Mat undistortedFrame = cameraCalibrator_.undistortImage(processedFrame);
                    // éªŒè¯å»ç•¸å˜ç»“æœæ˜¯å¦æœ‰æ•ˆ
                    if (!undistortedFrame.empty() && 
                        undistortedFrame.cols == processedFrame.cols && 
                        undistortedFrame.rows == processedFrame.rows) {
                        processedFrame = undistortedFrame;
                    } else {
                        cerr << "Warning: Undistortion returned invalid result, using original frame" << endl;
                    }
                } catch (const cv::Exception& e) {
                    cerr << "OpenCV error in undistortion: " << e.what() << endl;
                    // ç»§ç»­ä½¿ç”¨åŸå§‹å¸§ï¼Œä¸è¿›è¡Œå»ç•¸å˜
                } catch (const std::exception& e) {
                    cerr << "Error in undistortion: " << e.what() << endl;
                    // ç»§ç»­ä½¿ç”¨åŸå§‹å¸§ï¼Œä¸è¿›è¡Œå»ç•¸å˜
                }
            }
            
            // å¦‚æœå¤„äºç›¸æœºæ ‡å®šæ¨¡å¼ï¼Œä½¿ç”¨è½»é‡çº§æ˜¾ç¤ºå¤„ç†
            if (cameraCalibrationMode_) {
                try {
                    // å¯¹æ˜¾ç¤ºåˆ†è¾¨ç‡çš„å¸§è¿›è¡Œè½»é‡çº§å¤„ç†
                    cv::Mat displayFrame;
                    if (processedFrame.cols != displayWidth_ || processedFrame.rows != displayHeight_) {
                        cv::resize(processedFrame, displayFrame, cv::Size(displayWidth_, displayHeight_));
                    } else {
                        displayFrame = processedFrame.clone();
                    }
                    
                    // åªåœ¨æ˜¾ç¤ºå¸§ä¸Šåšç®€å•çš„æ£‹ç›˜æ ¼æ£€æµ‹å’Œç»˜åˆ¶ï¼ˆä½ç²¾åº¦ï¼Œå¿«é€Ÿï¼‰
                    std::vector<cv::Point2f> corners;
                    bool found = false;
                    
                    // ä½¿ç”¨æ›´å®½æ¾çš„æ£€æµ‹æ¡ä»¶è¿›è¡Œå¿«é€Ÿæ£€æµ‹
                    int quickFlags = cv::CALIB_CB_ADAPTIVE_THRESH;
                    found = cv::findChessboardCorners(displayFrame, cameraCalibrator_.getBoardSize(), corners, quickFlags);
                    
                    if (found) {
                        // ç¼©æ”¾è§’ç‚¹åæ ‡å›åŸå§‹å¸§æ¯”ä¾‹ï¼ˆç”¨äºç²¾ç¡®æ˜¾ç¤ºï¼‰
                        float scaleX = (float)processedFrame.cols / displayWidth_;
                        float scaleY = (float)processedFrame.rows / displayHeight_;
                        for (auto& corner : corners) {
                            corner.x *= scaleX;
                            corner.y *= scaleY;
                        }
                        
                        cv::drawChessboardCorners(processedFrame, cameraCalibrator_.getBoardSize(), corners, found);
                        cv::putText(processedFrame, "Chessboard OK", cv::Point(processedFrame.cols - 160, 30),
                                  cv::FONT_HERSHEY_SIMPLEX, 0.6, cv::Scalar(0, 255, 0), 2, cv::LINE_AA);
                    } else {
                        cv::putText(processedFrame, "Searching...", cv::Point(processedFrame.cols - 150, 30),
                                  cv::FONT_HERSHEY_SIMPLEX, 0.6, cv::Scalar(0, 100, 255), 2, cv::LINE_AA);
                    }
                    
                } catch (const std::exception& e) {
                    cerr << "Error in chessboard visualization: " << e.what() << endl;
                }
            } else if (calibrationMode_) {
                // åæ ‡å˜æ¢æ ‡å®šæ¨¡å¼çš„ç®€æ´æç¤º
                cv::putText(processedFrame, "Click to add point", cv::Point(processedFrame.cols - 180, 30),
                          cv::FONT_HERSHEY_SIMPLEX, 0.6, cv::Scalar(255, 200, 0), 2, cv::LINE_AA);
            }
            
            // åŒæµç­–ç•¥ï¼šå­˜å‚¨ä¸¤ç§åˆ†è¾¨ç‡çš„å¸§
            {
                std::lock_guard<std::mutex> lock(mutex_);
                if (cameraCalibrationMode_) {
                    // æ ‡å®šæ¨¡å¼ï¼šå­˜å‚¨æ˜¾ç¤ºç”¨çš„å¤„ç†å¸§å’ŒåŸå§‹æ£€æµ‹å¸§
                    frame_ = processedFrame;        // æ˜¾ç¤ºç”¨å¤„ç†å¸§ï¼ˆå¸¦è§’ç‚¹ç»˜åˆ¶ï¼‰
                    detectionFrame_ = frame.clone(); // åŸå§‹å¸§ç”¨äºç²¾ç¡®æ£€æµ‹
                } else {
                    // æ­£å¸¸æ¨¡å¼ï¼šç›´æ¥å­˜å‚¨å¤„ç†å¸§
                    frame_ = processedFrame;
                    detectionFrame_ = frame.clone(); // ä¿æŒåŒæ­¥
                }
            }
        } else {
            cerr << "Error: Failed to read frame" << endl;
            this_thread::sleep_for(chrono::milliseconds(100));
        }
    }
}

// ç›¸æœºæ ‡å®šç›¸å…³æ–¹æ³•å®ç°
bool VideoStreamer::isCameraCalibrationMode() const {
    return cameraCalibrationMode_;
}

void VideoStreamer::setCameraCalibrationMode(bool mode) {
    cameraCalibrationMode_ = mode;
}

bool VideoStreamer::addCameraCalibrationImage() {
    // ä½¿ç”¨é«˜åˆ†è¾¨ç‡æ£€æµ‹å¸§è¿›è¡Œæ ‡å®š
    cv::Mat detectionFrame = getDetectionFrame();
    
    if (detectionFrame.empty()) {
        std::cerr << "No detection frame available for calibration" << std::endl;
        return false;
    }
    
    return cameraCalibrator_.addCalibrationImage(detectionFrame);
}

bool VideoStreamer::calibrateCamera() {
    return cameraCalibrator_.calibrate();
}

bool VideoStreamer::saveCameraCalibrationData(const std::string& filename) {
    std::string filepath = filename.empty() ? cameraCalibrationFilePath_ : filename;
    return cameraCalibrator_.saveCalibrationData(filepath);
}

bool VideoStreamer::loadCameraCalibrationData(const std::string& filename) {
    std::string filepath = filename.empty() ? cameraCalibrationFilePath_ : filename;
    return cameraCalibrator_.loadCalibrationData(filepath);
}

cv::Mat VideoStreamer::getCameraMatrix() const {
    return cameraCalibrator_.getCameraMatrix();
}

cv::Mat VideoStreamer::getDistCoeffs() const {
    return cameraCalibrator_.getDistCoeffs();
}

double VideoStreamer::getCalibrationError() const {
    return cameraCalibrator_.getCalibrationError();
}

size_t VideoStreamer::getCalibrationImageCount() const {
    return cameraCalibrator_.getImageCount();
}

void VideoStreamer::setChessboardSize(int width, int height) {
    cameraCalibrator_.setChessboardSize(width, height);
}

void VideoStreamer::setSquareSize(float size) {
    cameraCalibrator_.setSquareSize(size);
}

void VideoStreamer::setBlurKernelSize(int size) {
    cameraCalibrator_.setBlurKernelSize(size);
}

void VideoStreamer::setQualityCheckLevel(int level) {
    CameraCalibrator::QualityCheckLevel qualityLevel;
    switch (level) {
        case 0: qualityLevel = CameraCalibrator::STRICT; break;
        case 1: qualityLevel = CameraCalibrator::BALANCED; break;
        case 2: qualityLevel = CameraCalibrator::PERMISSIVE; break;
        default: qualityLevel = CameraCalibrator::BALANCED; break;
    }
    cameraCalibrator_.setQualityCheckLevel(qualityLevel);
}

int VideoStreamer::getBlurKernelSize() const {
    return cameraCalibrator_.getBlurKernelSize();
}

bool VideoStreamer::isCameraCalibrated() const {
    return cameraCalibrator_.isCalibrated();
}

// æ–°å¢ï¼šç›¸æœºæ ‡å®šä¼šè¯ç®¡ç†æ–¹æ³•å®ç°
void VideoStreamer::startNewCameraCalibrationSession() {
    std::cout << "VideoStreamer: Starting new camera calibration session" << std::endl;
    cameraCalibrator_.startNewCalibrationSession();
    
    // å‘é€ä¼šè¯çŠ¶æ€æ›´æ–°åˆ°å®¢æˆ·ç«¯
    std::string response = "{\"type\":\"camera_calibration_session_started\","
                          "\"message\":\"New calibration session started\","
                          "\"image_count\":0}";
    
    // å¹¿æ’­åˆ°æ‰€æœ‰è¿æ¥çš„å®¢æˆ·ç«¯
    std::lock_guard<std::mutex> lock(conn_mutex_);
    for (auto& conn : connections_) {
        try {
            conn->send_text(response);
        } catch (const std::exception& e) {
            std::cerr << "Error sending session start notification: " << e.what() << std::endl;
        }
    }
}

void VideoStreamer::clearCurrentCameraCalibrationSession() {
    std::cout << "VideoStreamer: Clearing current camera calibration session" << std::endl;
    cameraCalibrator_.clearCurrentSession();
    
    // å‘é€ä¼šè¯æ¸…é™¤é€šçŸ¥åˆ°å®¢æˆ·ç«¯
    std::string response = "{\"type\":\"camera_calibration_session_cleared\","
                          "\"message\":\"Current session cleared\","
                          "\"image_count\":0}";
    
    // å¹¿æ’­åˆ°æ‰€æœ‰è¿æ¥çš„å®¢æˆ·ç«¯
    std::lock_guard<std::mutex> lock(conn_mutex_);
    for (auto& conn : connections_) {
        try {
            conn->send_text(response);
        } catch (const std::exception& e) {
            std::cerr << "Error sending session clear notification: " << e.what() << std::endl;
        }
    }
}

size_t VideoStreamer::getCurrentSessionImageCount() const {
    return cameraCalibrator_.getCurrentSessionImageCount();
}

bool VideoStreamer::startAutoCalibrationCapture(int durationSeconds, int intervalMs) {
    // å¦‚æœå·²ç»åœ¨è‡ªåŠ¨é‡‡é›†ä¸­ï¼Œè¿”å›false
    if (autoCapturing_) {
        std::cerr << "Auto calibration capture already running" << std::endl;
        return false;
    }
    
    // å¦‚æœä¸åœ¨ç›¸æœºæ ‡å®šæ¨¡å¼ï¼Œè¿”å›false
    if (!cameraCalibrationMode_) {
        std::cerr << "Must be in camera calibration mode to start auto capture" << std::endl;
        return false;
    }
    
    // è®¾ç½®è‡ªåŠ¨é‡‡é›†æ ‡å¿—
    autoCapturing_ = true;
    
    // å¯åŠ¨è‡ªåŠ¨é‡‡é›†çº¿ç¨‹
    autoCapturingThread_ = std::thread(&VideoStreamer::autoCalibrationCaptureThread, this, durationSeconds, intervalMs);
    autoCapturingThread_.detach();
    
    std::cout << "Started auto calibration capture for " << durationSeconds << " seconds with " 
              << intervalMs << "ms interval" << std::endl;
    
    return true;
}

bool VideoStreamer::stopAutoCalibrationCapture() {
    // å¦‚æœæ²¡æœ‰åœ¨è‡ªåŠ¨é‡‡é›†ä¸­ï¼Œè¿”å›false
    if (!autoCapturing_) {
        std::cerr << "Auto calibration capture not running" << std::endl;
        return false;
    }
    
    // è®¾ç½®è‡ªåŠ¨é‡‡é›†æ ‡å¿—ä¸ºfalse
    autoCapturing_ = false;
    
    std::cout << "Stopped auto calibration capture" << std::endl;
    
    return true;
}

void VideoStreamer::autoCalibrationCaptureThread(int durationSeconds, int intervalMs) {
    // è®¡ç®—ç»“æŸæ—¶é—´
    auto endTime = std::chrono::steady_clock::now() + std::chrono::seconds(durationSeconds);
    int successCount = 0;
    int attemptCount = 0;
    
    std::cout << "=== AUTO CALIBRATION CAPTURE THREAD STARTED ===" << std::endl;
    std::cout << "Duration: " << durationSeconds << " seconds, Interval: " << intervalMs << " ms" << std::endl;
    std::cout << "Initial image count: " << cameraCalibrator_.getCurrentSessionImageCount() << std::endl;
    
    // å¾ªç¯ç›´åˆ°è¾¾åˆ°ç»“æŸæ—¶é—´æˆ–åœæ­¢æ ‡å¿—è¢«è®¾ç½®
    while (autoCapturing_ && std::chrono::steady_clock::now() < endTime) {
        // è·å–ç”¨äºæ£€æµ‹çš„é«˜åˆ†è¾¨ç‡å¸§
        cv::Mat detectionFrame = getDetectionFrame();
        
        if (!detectionFrame.empty()) {
            attemptCount++;
            std::cout << "\n--- Attempt " << attemptCount << " ---" << std::endl;
            std::cout << "Frame size: " << detectionFrame.cols << "x" << detectionFrame.rows << std::endl;
            
            // å°è¯•æ£€æµ‹æ£‹ç›˜æ ¼å¹¶æ·»åŠ æ ‡å®šå›¾åƒ
            std::vector<cv::Point2f> corners;
            bool found = cameraCalibrator_.detectChessboard(detectionFrame, corners, true);  // ä½¿ç”¨å®Œæ•´çš„è°ƒè¯•æ£€æµ‹
            
            std::cout << "Chessboard detection result: " << (found ? "SUCCESS" : "FAILED") << std::endl;
            if (found) {
                std::cout << "Detected " << corners.size() << " corners" << std::endl;
                
                // è®°å½•æ·»åŠ å‰çš„å›¾ç‰‡æ•°é‡
                size_t beforeCount = cameraCalibrator_.getCurrentSessionImageCount();
                std::cout << "Image count before adding: " << beforeCount << std::endl;
                
                // å¦‚æœæ£€æµ‹æˆåŠŸï¼Œæ·»åŠ æ ‡å®šå›¾åƒ
                bool addSuccess = cameraCalibrator_.addCalibrationImage(detectionFrame);
                
                // è®°å½•æ·»åŠ åçš„å›¾ç‰‡æ•°é‡
                size_t afterCount = cameraCalibrator_.getCurrentSessionImageCount();
                std::cout << "Add calibration image result: " << (addSuccess ? "SUCCESS" : "FAILED") << std::endl;
                std::cout << "Image count after adding: " << afterCount << std::endl;
                
                if (addSuccess) {
                    successCount++;
                    std::cout << "âœ… Successfully added calibration image " << successCount 
                              << " (attempt " << attemptCount << ")" << std::endl;
                    std::cout << "Total images in session: " << afterCount << std::endl;
                    
                    // ç«‹å³å‘æ‰€æœ‰WebSocketå®¢æˆ·ç«¯å‘é€æ›´æ–°çš„æ ‡å®šçŠ¶æ€
                    std::string status_message = std::string("{\"type\":\"camera_calibration_status\",")
                                          + "\"calibration_mode\":"
                                          + (cameraCalibrationMode_ ? "true" : "false") + ","
                                          + "\"calibrated\":"
                                          + (cameraCalibrator_.isCalibrated() ? "true" : "false") + ","
                                          + "\"image_count\":"
                                          + std::to_string(cameraCalibrator_.getImageCount()) + ","
                                          + "\"current_session_count\":"
                                          + std::to_string(cameraCalibrator_.getCurrentSessionImageCount()) + ","
                                          + "\"saved_count\":"
                                          + std::to_string(cameraCalibrator_.getImageCount()) + ","
                                          + "\"auto_capture_progress\": true}";
                    
                    std::cout << "Sending WebSocket message: " << status_message << std::endl;
                    
                    std::lock_guard<std::mutex> lock(conn_mutex_);
                    std::cout << "Number of WebSocket connections: " << connections_.size() << std::endl;
                    for (auto conn : connections_) {
                        if (conn) {
                            try {
                                conn->send_text(status_message);
                                std::cout << "Message sent to WebSocket client successfully" << std::endl;
                            } catch (const std::exception& e) {
                                std::cout << "Error sending WebSocket message: " << e.what() << std::endl;
                            }
                        }
                    }
                } else {
                    std::cout << "âŒ Failed to add calibration image (quality check failed)" << std::endl;
                }
            } else {
                std::cout << "âŒ No chessboard detected in this frame" << std::endl;
            }
        } else {
            std::cout << "âŒ Empty detection frame" << std::endl;
        }
        
        // ç­‰å¾…æŒ‡å®šçš„é—´éš”æ—¶é—´
        std::this_thread::sleep_for(std::chrono::milliseconds(intervalMs));
    }
    
    // è®¾ç½®è‡ªåŠ¨é‡‡é›†æ ‡å¿—ä¸ºfalse
    autoCapturing_ = false;
    
    std::cout << "\n=== AUTO CALIBRATION CAPTURE COMPLETED ===" << std::endl;
    std::cout << "Final results:" << std::endl;
    std::cout << "- Attempts: " << attemptCount << std::endl;
    std::cout << "- Successful captures: " << successCount << std::endl;
    std::cout << "- Final image count in session: " << cameraCalibrator_.getCurrentSessionImageCount() << std::endl;
    
    // å‘æ‰€æœ‰WebSocketå®¢æˆ·ç«¯å‘é€è‡ªåŠ¨é‡‡é›†å®Œæˆçš„æ¶ˆæ¯
    std::string completion_message = std::string("{\"type\":\"auto_capture_completed\",")
                              + "\"success_count\":"
                              + std::to_string(successCount) + ","
                              + "\"attempt_count\":"
                              + std::to_string(attemptCount) + ","
                              + "\"image_count\":"
                              + std::to_string(cameraCalibrator_.getImageCount()) + "}";
    
    std::cout << "Sending completion message: " << completion_message << std::endl;
    
    std::lock_guard<std::mutex> lock(conn_mutex_);
    for (auto conn : connections_) {
        if (conn) {
            try {
                conn->send_text(completion_message);
                std::cout << "Completion message sent to WebSocket client" << std::endl;
            } catch (const std::exception& e) {
                std::cout << "Error sending completion message: " << e.what() << std::endl;
            }
        }
    }
}

// åŒåˆ†è¾¨ç‡æ”¯æŒæ–¹æ³•
void VideoStreamer::setDisplayResolution(int width, int height) {
    displayWidth_ = width;
    displayHeight_ = height;
}

void VideoStreamer::setDetectionResolution(int width, int height) {
    detectionWidth_ = width;
    detectionHeight_ = height;
}

cv::Mat VideoStreamer::getDisplayFrame() {
    std::lock_guard<std::mutex> lock(mutex_);
    if (frame_.empty()) return cv::Mat();
    
    // å¦‚æœå½“å‰å¸§åˆ†è¾¨ç‡ä¸æ˜¾ç¤ºåˆ†è¾¨ç‡ä¸åŒï¼Œè¿›è¡Œç¼©æ”¾
    if (frame_.cols != displayWidth_ || frame_.rows != displayHeight_) {
        cv::Mat displayFrame;
        cv::resize(frame_, displayFrame, cv::Size(displayWidth_, displayHeight_));
        return displayFrame;
    }
    
    return frame_.clone();
}

cv::Mat VideoStreamer::getDetectionFrame() {
    std::lock_guard<std::mutex> lock(mutex_);
    if (detectionFrame_.empty()) return cv::Mat();
    
    // æ£€æµ‹æ€»æ˜¯ä½¿ç”¨åŸå§‹é«˜åˆ†è¾¨ç‡å¸§
    return detectionFrame_.clone();
}

// ç›¸æœºæ ¡æ­£æ§åˆ¶æ–¹æ³•
void VideoStreamer::setCameraCorrectionEnabled(bool enabled) {
    cameraCorrectionEnabled_ = enabled;
    std::cout << "ğŸ“¸ [CAMERA CORRECTION] Set to: " << (enabled ? "enabled" : "disabled") << std::endl;
}

bool VideoStreamer::isCameraCorrectionEnabled() const {
    return cameraCorrectionEnabled_;
}
